{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a8da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========\n",
    "# Code From : https://www.kaggle.com/yasufuminakama/inchi-preprocess-2\n",
    "# ===========\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99ef695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (9923222, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923217</th>\n",
       "      <td>gggg07499032</td>\n",
       "      <td>InChI=1S/C24H24N2O2/c27-24(28)22-12-16-26(17-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923218</th>\n",
       "      <td>gggg07499033</td>\n",
       "      <td>InChI=1S/C19H19NO2S/c1-12-5-3-4-6-15(12)10-23-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923219</th>\n",
       "      <td>gggg07499034</td>\n",
       "      <td>InChI=1S/C16H10N4O3/c17-9-13-12(15-2-1-7-23-15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923220</th>\n",
       "      <td>gggg07499035</td>\n",
       "      <td>InChI=1S/C26H24N2O5/c1-16-23(32-17(2)26(30)28-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923221</th>\n",
       "      <td>gggg00000000</td>\n",
       "      <td>InChI=1S/C18H19NO4S/c1-21-14-4-2-13(3-5-14)11-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9923222 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id                                              InChI\n",
       "0        000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...\n",
       "1        000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...\n",
       "2        0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...\n",
       "3        000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...\n",
       "4        000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...\n",
       "...               ...                                                ...\n",
       "9923217  gggg07499032  InChI=1S/C24H24N2O2/c27-24(28)22-12-16-26(17-1...\n",
       "9923218  gggg07499033  InChI=1S/C19H19NO2S/c1-12-5-3-4-6-15(12)10-23-...\n",
       "9923219  gggg07499034  InChI=1S/C16H10N4O3/c17-9-13-12(15-2-1-7-23-15...\n",
       "9923220  gggg07499035  InChI=1S/C26H24N2O5/c1-16-23(32-17(2)26(30)28-...\n",
       "9923221  gggg00000000  InChI=1S/C18H19NO4S/c1-21-14-4-2-13(3-5-14)11-...\n",
       "\n",
       "[9923222 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('../../molecular_data/total.csv')\n",
    "print(f'train.shape: {train.shape}')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79efdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Preprocess functions\n",
    "# ====================================================\n",
    "def split_form(form):\n",
    "    string = ''\n",
    "    for i in re.findall(r\"[A-Z][^A-Z]*\", form):\n",
    "        elem = re.match(r\"\\D+\", i).group()\n",
    "        num = i.replace(elem, \"\")\n",
    "        if num == \"\":\n",
    "            string += f\"{elem} \"\n",
    "        else:\n",
    "            string += f\"{elem} {str(num)} \"\n",
    "    return string.rstrip(' ')\n",
    "\n",
    "def split_form2(form):\n",
    "    string = ''\n",
    "    for i in re.findall(r\"[a-z][^a-z]*\", form):\n",
    "        elem = i[0]\n",
    "        num = i.replace(elem, \"\").replace('/', \"\")\n",
    "        num_string = ''\n",
    "        for j in re.findall(r\"[0-9]+[^0-9]*\", num):\n",
    "            num_list = list(re.findall(r'\\d+', j))\n",
    "            assert len(num_list) == 1, f\"len(num_list) != 1\"\n",
    "            _num = num_list[0]\n",
    "            if j == _num:\n",
    "                num_string += f\"{_num} \"\n",
    "            else:\n",
    "                extra = j.replace(_num, \"\")\n",
    "                num_string += f\"{_num} {' '.join(list(extra))} \"\n",
    "        string += f\"/{elem} {num_string}\"\n",
    "    return string.rstrip(' ')\n",
    "\n",
    "# ====================================================\n",
    "# Tokenizer\n",
    "# ====================================================\n",
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        vocab = set()\n",
    "        for text in texts:\n",
    "            vocab.update(text.split(' '))\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        self.itos = {item[1]: item[0] for item in self.stoi.items()}\n",
    "        \n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = []\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        return sequence\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = self.text_to_sequence(text)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = self.sequence_to_text(sequence)\n",
    "            texts.append(text)\n",
    "        return texts\n",
    "    \n",
    "    def predict_caption(self, sequence):\n",
    "        caption = ''\n",
    "        for i in sequence:\n",
    "            if i == self.stoi['<eos>'] or i == self.stoi['<pad>']:\n",
    "                break\n",
    "            caption += self.itos[i]\n",
    "        return caption\n",
    "    \n",
    "    def predict_captions(self, sequences):\n",
    "        captions = []\n",
    "        for sequence in sequences:\n",
    "            caption = self.predict_caption(sequence)\n",
    "            captions.append(caption)\n",
    "        return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91419ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # preprocess train.csv\n",
    "    # ====================================================\n",
    "    train['InChI_1'] = train['InChI'].progress_apply(lambda x: x.split('/')[1])\n",
    "    train['InChI_text'] = train['InChI_1'].progress_apply(split_form) + ' ' + \\\n",
    "                            train['InChI'].apply(lambda x: '/'.join(x.split('/')[2:])).progress_apply(split_form2).values\n",
    "    # ====================================================\n",
    "    # create tokenizer\n",
    "    # ====================================================\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train['InChI_text'].values)\n",
    "    torch.save(tokenizer, 'tokenizer2.pth')\n",
    "    print('Saved tokenizer')\n",
    "    # ====================================================\n",
    "    # preprocess train.csv\n",
    "    # ====================================================\n",
    "    lengths = []\n",
    "    tk0 = tqdm(train['InChI_text'].values, total=len(train))\n",
    "    for text in tk0:\n",
    "        seq = tokenizer.text_to_sequence(text)\n",
    "        length = len(seq) - 2\n",
    "        lengths.append(length)\n",
    "    train['InChI_length'] = lengths\n",
    "    train.to_pickle('train2.pkl')\n",
    "    print('Saved preprocessed train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b068d47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e103399910de43268ee4ce06eef359fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9923222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68056d31a8fb451d9bdf40151a3c5659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9923222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac09e3b277f4eed8fd1298c3e0ece2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9923222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d9bc2f6f974aad8758571b85bbd3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9923222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed train.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b394f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
