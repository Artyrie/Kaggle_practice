{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2904f519",
   "metadata": {},
   "source": [
    "## Code from\n",
    "\n",
    "<< https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter >>\n",
    "* Kaggle : Y.Nakama, yasufuminakama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effe38c",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0efdf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, Blur\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d512cb",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b606e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  7\n",
      "1.7.1 cuda:7\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() : \n",
    "    GPU_NUM = 7 # 원하는 GPU 번호 입력\n",
    "    DEVICE = torch.device(f'cuda:{GPU_NUM}')\n",
    "    torch.cuda.set_device(DEVICE) # change allocation of current GPU\n",
    "    print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "else : \n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print(torch.__version__, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6544d4a8",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eeb3ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../molecular_data/'\n",
    "TRAIN_DIR = PATH + 'train'\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "class CFG:\n",
    "    debug = False\n",
    "    apex = False\n",
    "    max_len = 275\n",
    "    print_freq = 1\n",
    "    num_workers = 0\n",
    "    model_name = 'efficientnet_b2'\n",
    "    enc_size = 1408\n",
    "    samp_size = 100000\n",
    "    size = 288\n",
    "    scheduler = 'CosineAnnealingLR' \n",
    "    epochs = 1 \n",
    "    T_max = 4  \n",
    "    encoder_lr = 1e-4\n",
    "    decoder_lr = 4e-4\n",
    "    min_lr = 1e-6\n",
    "    batch_size = 32\n",
    "    weight_decay = 1e-6\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 10\n",
    "    attention_dim = 256\n",
    "    embed_dim = 512\n",
    "    decoder_dim = 512\n",
    "    decoder_layers = 2     # number of LSTM layers\n",
    "    dropout = 0.5\n",
    "    seed = 42\n",
    "    n_fold = 5\n",
    "    trn_fold = [0, 1, 2, 3, 4]\n",
    "    train = True\n",
    "    \n",
    "    prev_model = 'efficientnet_b2_fold0_best.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f77d3d",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c3b4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChI_1</th>\n",
       "      <th>InChI_text</th>\n",
       "      <th>InChI_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>C13H20OS</td>\n",
       "      <td>C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>C21H30O4</td>\n",
       "      <td>C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>C24H23N5O4</td>\n",
       "      <td>C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>C17H24N2O4S</td>\n",
       "      <td>C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>C10H19N3O2S</td>\n",
       "      <td>C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "       InChI_1                                         InChI_text  \\\n",
       "0     C13H20OS  C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...   \n",
       "1     C21H30O4  C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...   \n",
       "2   C24H23N5O4  C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...   \n",
       "3  C17H24N2O4S  C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...   \n",
       "4  C10H19N3O2S  C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...   \n",
       "\n",
       "   InChI_length  \n",
       "0            59  \n",
       "1           108  \n",
       "2           112  \n",
       "3           108  \n",
       "4            72  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('train2.pkl')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4af58e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5ab4d",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4d85863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.stoi: {'': 0, '(': 1, ')': 2, '*': 3, '+': 4, ',': 5, '-': 6, '.': 7, '/b': 8, '/c': 9, '/h': 10, '/i': 11, '/m': 12, '/p': 13, '/q': 14, '/s': 15, '/t': 16, '0': 17, '00': 18, '000': 19, '0000': 20, '00000': 21, '001': 22, '01': 23, '010': 24, '0100': 25, '011': 26, '1': 27, '10': 28, '10.': 29, '10.2': 30, '10.3': 31, '10.4': 32, '10.5': 33, '10.6': 34, '100': 35, '101': 36, '102': 37, '103': 38, '104': 39, '105': 40, '106': 41, '107': 42, '108': 43, '109': 44, '11': 45, '11.': 46, '11.2': 47, '11.3': 48, '11.4': 49, '11.5': 50, '110': 51, '111': 52, '1111': 53, '11111': 54, '112': 55, '113': 56, '114': 57, '115': 58, '116': 59, '117': 60, '118': 61, '119': 62, '12': 63, '12.': 64, '12.12': 65, '12.2': 66, '12.3': 67, '12.4': 68, '12.5': 69, '12.6': 70, '12.8': 71, '120': 72, '121': 73, '122': 74, '123': 75, '124': 76, '125': 77, '126': 78, '127': 79, '128': 80, '129': 81, '13': 82, '13.': 83, '13.2': 84, '13.3': 85, '13.4': 86, '13.5': 87, '130': 88, '131': 89, '132': 90, '133': 91, '134': 92, '135': 93, '136': 94, '137': 95, '138': 96, '139': 97, '14': 98, '14.': 99, '14.2': 100, '14.3': 101, '14.4': 102, '14.5': 103, '14.6': 104, '140': 105, '141': 106, '142': 107, '143': 108, '144': 109, '145': 110, '146': 111, '147': 112, '148': 113, '149': 114, '15': 115, '15.': 116, '15.2': 117, '15.3': 118, '15.4': 119, '15.5': 120, '15.6': 121, '150': 122, '151': 123, '152': 124, '153': 125, '154': 126, '155': 127, '156': 128, '157': 129, '158': 130, '159': 131, '16': 132, '16.': 133, '16.2': 134, '16.3': 135, '16.4': 136, '16.5': 137, '16.7': 138, '160': 139, '161': 140, '162': 141, '163': 142, '164': 143, '165': 144, '166': 145, '167': 146, '168': 147, '169': 148, '17': 149, '17.': 150, '17.2': 151, '17.3': 152, '17.4': 153, '170': 154, '171': 155, '172': 156, '173': 157, '174': 158, '175': 159, '176': 160, '177': 161, '178': 162, '179': 163, '18': 164, '18.': 165, '18.2': 166, '18.3': 167, '18.4': 168, '180': 169, '181': 170, '182': 171, '183': 172, '184': 173, '185': 174, '186': 175, '187': 176, '188': 177, '189': 178, '19': 179, '19.': 180, '19.2': 181, '19.3': 182, '190': 183, '191': 184, '192': 185, '192.': 186, '193': 187, '194': 188, '195': 189, '196': 190, '197': 191, '198': 192, '199': 193, '2': 194, '2.': 195, '2.10': 196, '2.11': 197, '2.12': 198, '2.13': 199, '2.14': 200, '2.16': 201, '2.18': 202, '2.2': 203, '2.20': 204, '2.22': 205, '2.25': 206, '2.3': 207, '2.30': 208, '2.38': 209, '2.4': 210, '2.5': 211, '2.6': 212, '2.60': 213, '2.7': 214, '2.8': 215, '2.9': 216, '20': 217, '20.': 218, '20.2': 219, '20.3': 220, '20.4': 221, '20.6': 222, '200': 223, '201': 224, '202': 225, '203': 226, '204': 227, '205': 228, '206': 229, '207': 230, '208': 231, '209': 232, '21': 233, '21.': 234, '21.3': 235, '21.4': 236, '210': 237, '211': 238, '212': 239, '213': 240, '214': 241, '215': 242, '216': 243, '217': 244, '218': 245, '219': 246, '22': 247, '22.': 248, '22.12': 249, '22.4': 250, '220': 251, '221': 252, '222': 253, '223': 254, '224': 255, '225': 256, '226': 257, '227': 258, '228': 259, '229': 260, '23': 261, '23.': 262, '23.2': 263, '230': 264, '231': 265, '232': 266, '233': 267, '234': 268, '235': 269, '236': 270, '237': 271, '238': 272, '239': 273, '24': 274, '24.': 275, '24.3': 276, '24.4': 277, '240': 278, '241': 279, '242': 280, '243': 281, '244': 282, '245': 283, '246': 284, '247': 285, '248': 286, '249': 287, '25': 288, '25.': 289, '25.2': 290, '25.3': 291, '250': 292, '251': 293, '26': 294, '26.': 295, '262': 296, '264': 297, '269': 298, '27': 299, '27.8': 300, '270': 301, '28': 302, '28.': 303, '288': 304, '29': 305, '29.': 306, '29.2': 307, '292': 308, '294': 309, '3': 310, '3.': 311, '3.10': 312, '3.11': 313, '3.12': 314, '3.15': 315, '3.2': 316, '3.3': 317, '3.4': 318, '3.5': 319, '3.6': 320, '3.7': 321, '3.8': 322, '3.9': 323, '30': 324, '30.': 325, '31': 326, '31.': 327, '32': 328, '328': 329, '33': 330, '33.': 331, '34': 332, '34.': 333, '348': 334, '35': 335, '35.': 336, '36': 337, '36.': 338, '37': 339, '37.': 340, '37.2': 341, '37.3': 342, '38': 343, '38.': 344, '39': 345, '39.': 346, '4': 347, '4.': 348, '4.10': 349, '4.11': 350, '4.12': 351, '4.13': 352, '4.17': 353, '4.19': 354, '4.2': 355, '4.20': 356, '4.21': 357, '4.26': 358, '4.3': 359, '4.4': 360, '4.40': 361, '4.5': 362, '4.6': 363, '4.61': 364, '4.7': 365, '4.8': 366, '4.9': 367, '40': 368, '40.': 369, '41': 370, '41.': 371, '42': 372, '43': 373, '43.': 374, '44': 375, '45': 376, '45.': 377, '46': 378, '47': 379, '48': 380, '48.': 381, '49': 382, '49.': 383, '5': 384, '5.': 385, '5.10': 386, '5.12': 387, '5.15': 388, '5.18': 389, '5.2': 390, '5.3': 391, '5.4': 392, '5.5': 393, '5.6': 394, '5.7': 395, '5.8': 396, '5.9': 397, '50': 398, '50.': 399, '51': 400, '52': 401, '53': 402, '53.': 403, '54': 404, '55': 405, '56': 406, '56.': 407, '57': 408, '57.': 409, '58': 410, '59': 411, '6': 412, '6.': 413, '6.10': 414, '6.11': 415, '6.12': 416, '6.2': 417, '6.22': 418, '6.25': 419, '6.3': 420, '6.38': 421, '6.4': 422, '6.5': 423, '6.6': 424, '6.7': 425, '6.8': 426, '6.9': 427, '60': 428, '61': 429, '61.': 430, '62': 431, '63': 432, '64': 433, '65': 434, '66': 435, '67': 436, '68': 437, '69': 438, '7': 439, '7.': 440, '7.11': 441, '7.2': 442, '7.3': 443, '7.4': 444, '7.5': 445, '7.6': 446, '7.7': 447, '7.9': 448, '70': 449, '71': 450, '72': 451, '73': 452, '74': 453, '75': 454, '76': 455, '77': 456, '78': 457, '79': 458, '8': 459, '8.': 460, '8.12': 461, '8.13': 462, '8.16': 463, '8.2': 464, '8.21': 465, '8.3': 466, '8.4': 467, '8.5': 468, '8.6': 469, '8.7': 470, '8.8': 471, '8.9': 472, '80': 473, '81': 474, '82': 475, '83': 476, '84': 477, '85': 478, '86': 479, '87': 480, '88': 481, '89': 482, '9': 483, '9.': 484, '9.2': 485, '9.3': 486, '9.4': 487, '9.5': 488, '9.6': 489, '90': 490, '91': 491, '92': 492, '93': 493, '94': 494, '95': 495, '96': 496, '97': 497, '98': 498, '99': 499, ';': 500, '?': 501, 'Ac': 502, 'Ac.': 503, 'Ag': 504, 'Ag.': 505, 'Al': 506, 'Al.': 507, 'Am': 508, 'Am.': 509, 'Ar': 510, 'Ar.': 511, 'As': 512, 'As.': 513, 'At': 514, 'Au': 515, 'Au.': 516, 'B': 517, 'B.': 518, 'Ba': 519, 'Ba.': 520, 'Be': 521, 'Be.': 522, 'Bi': 523, 'Bi.': 524, 'Bk': 525, 'Bk.': 526, 'Br': 527, 'Br.': 528, 'C': 529, 'C.': 530, 'Ca': 531, 'Ca.': 532, 'Cd': 533, 'Cd.': 534, 'Ce': 535, 'Ce.': 536, 'Cf': 537, 'Cf.': 538, 'Cl': 539, 'Cl.': 540, 'Cm': 541, 'Cm.': 542, 'Co': 543, 'Co.': 544, 'Cr': 545, 'Cr.': 546, 'Cs': 547, 'Cs.': 548, 'Cu': 549, 'Cu.': 550, 'D': 551, 'Dy': 552, 'Dy.': 553, 'Er': 554, 'Er.': 555, 'Es': 556, 'Es.': 557, 'Eu': 558, 'Eu.': 559, 'F': 560, 'F.': 561, 'Fe': 562, 'Fe.': 563, 'Fm': 564, 'Fr': 565, 'Fr.': 566, 'Ga': 567, 'Ga.': 568, 'Gd': 569, 'Gd.': 570, 'Ge': 571, 'Ge.': 572, 'H': 573, 'H.': 574, 'He': 575, 'He.': 576, 'Hf': 577, 'Hf.': 578, 'Hg': 579, 'Hg.': 580, 'Ho': 581, 'Ho.': 582, 'I': 583, 'I.': 584, 'In': 585, 'In.': 586, 'Ir': 587, 'Ir.': 588, 'K': 589, 'K.': 590, 'Kr': 591, 'La': 592, 'La.': 593, 'Li': 594, 'Li.': 595, 'Lr': 596, 'Lu': 597, 'Lu.': 598, 'Md': 599, 'Mg': 600, 'Mg.': 601, 'Mn': 602, 'Mn.': 603, 'Mo': 604, 'Mo.': 605, 'N': 606, 'N.': 607, 'Na': 608, 'Na.': 609, 'Nb': 610, 'Nb.': 611, 'Nd': 612, 'Nd.': 613, 'Ne': 614, 'Ni': 615, 'Ni.': 616, 'No': 617, 'No.': 618, 'Np': 619, 'Np.': 620, 'O': 621, 'O.': 622, 'Os': 623, 'Os.': 624, 'P': 625, 'P.': 626, 'Pa': 627, 'Pa.': 628, 'Pb': 629, 'Pb.': 630, 'Pd': 631, 'Pd.': 632, 'Pm': 633, 'Po': 634, 'Po.': 635, 'Pr': 636, 'Pr.': 637, 'Pt': 638, 'Pt.': 639, 'Pu': 640, 'Ra': 641, 'Rb': 642, 'Rb.': 643, 'Re': 644, 'Re.': 645, 'Rh': 646, 'Rh.': 647, 'Rn': 648, 'Ru': 649, 'Ru.': 650, 'S': 651, 'S.': 652, 'Sb': 653, 'Sb.': 654, 'Sc': 655, 'Sc.': 656, 'Se': 657, 'Se.': 658, 'Si': 659, 'Si.': 660, 'Sm': 661, 'Sm.': 662, 'Sn': 663, 'Sn.': 664, 'Sr': 665, 'Sr.': 666, 'T': 667, 'Ta': 668, 'Ta.': 669, 'Tb': 670, 'Tb.': 671, 'Tc': 672, 'Tc.': 673, 'Te': 674, 'Te.': 675, 'Th': 676, 'Th.': 677, 'Ti': 678, 'Ti.': 679, 'Tl': 680, 'Tl.': 681, 'Tm': 682, 'Tm.': 683, 'U': 684, 'U.': 685, 'V': 686, 'V.': 687, 'W': 688, 'W.': 689, 'Xe': 690, 'Y': 691, 'Y.': 692, 'Yb': 693, 'Yb.': 694, 'Zn': 695, 'Zn.': 696, 'Zr': 697, 'Zr.': 698, '<sos>': 699, '<eos>': 700, '<pad>': 701}\n"
     ]
    }
   ],
   "source": [
    "# Code From https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter\n",
    "\n",
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        vocab = set()\n",
    "        for text in texts:\n",
    "            vocab.update(text.split(' '))\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        self.itos = {item[1]: item[0] for item in self.stoi.items()}\n",
    "        \n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = []\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        return sequence\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = self.text_to_sequence(text)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = self.sequence_to_text(sequence)\n",
    "            texts.append(text)\n",
    "        return texts\n",
    "    \n",
    "    def predict_caption(self, sequence):\n",
    "        caption = ''\n",
    "        for i in sequence:\n",
    "            if i == self.stoi['<eos>'] or i == self.stoi['<pad>']:\n",
    "                break\n",
    "            caption += self.itos[i]\n",
    "        return caption\n",
    "    \n",
    "    def predict_captions(self, sequences):\n",
    "        captions = []\n",
    "        for sequence in sequences:\n",
    "            caption = self.predict_caption(sequence)\n",
    "            captions.append(caption)\n",
    "        return captions\n",
    "\n",
    "tokenizer = torch.load('tokenizer2.pth')\n",
    "print(f\"tokenizer.stoi: {tokenizer.stoi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbacbf",
   "metadata": {},
   "source": [
    "## DF preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e1e4bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['InChI_length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cf02658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(img_name) : \n",
    "    return f\"{TRAIN_DIR}/{img_name[0]}/{img_name[1]}/{img_name[2]}/{img_name}.png\"\n",
    "\n",
    "train['path'] = train['image_id'].apply(get_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "052c0723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChI_1</th>\n",
       "      <th>InChI_text</th>\n",
       "      <th>InChI_length</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>C13H20OS</td>\n",
       "      <td>C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...</td>\n",
       "      <td>59</td>\n",
       "      <td>../../molecular_data/train/0/0/0/000011a64c74.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>C21H30O4</td>\n",
       "      <td>C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...</td>\n",
       "      <td>108</td>\n",
       "      <td>../../molecular_data/train/0/0/0/000019cc0cd2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>C24H23N5O4</td>\n",
       "      <td>C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...</td>\n",
       "      <td>112</td>\n",
       "      <td>../../molecular_data/train/0/0/0/0000252b6d2b.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>C17H24N2O4S</td>\n",
       "      <td>C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...</td>\n",
       "      <td>108</td>\n",
       "      <td>../../molecular_data/train/0/0/0/000026b49b7e.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>C10H19N3O2S</td>\n",
       "      <td>C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...</td>\n",
       "      <td>72</td>\n",
       "      <td>../../molecular_data/train/0/0/0/000026fc6c36.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "       InChI_1                                         InChI_text  \\\n",
       "0     C13H20OS  C 13 H 20 O S /c 1 - 9 ( 2 ) 8 - 15 - 13 - 6 -...   \n",
       "1     C21H30O4  C 21 H 30 O 4 /c 1 - 12 ( 22 ) 25 - 14 - 6 - 8...   \n",
       "2   C24H23N5O4  C 24 H 23 N 5 O 4 /c 1 - 14 - 13 - 15 ( 7 - 8 ...   \n",
       "3  C17H24N2O4S  C 17 H 24 N 2 O 4 S /c 1 - 12 ( 20 ) 18 - 13 (...   \n",
       "4  C10H19N3O2S  C 10 H 19 N 3 O 2 S /c 1 - 15 - 10 ( 14 ) 12 -...   \n",
       "\n",
       "   InChI_length                                               path  \n",
       "0            59  ../../molecular_data/train/0/0/0/000011a64c74.png  \n",
       "1           108  ../../molecular_data/train/0/0/0/000019cc0cd2.png  \n",
       "2           112  ../../molecular_data/train/0/0/0/0000252b6d2b.png  \n",
       "3           108  ../../molecular_data/train/0/0/0/000026b49b7e.png  \n",
       "4            72  ../../molecular_data/train/0/0/0/000026fc6c36.png  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eac068",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "330cc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset) : \n",
    "    def __init__(self, df, tokenizer, transform) :\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) : \n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index) : \n",
    "        image_name = self.df.image_id.iloc[index]\n",
    "        image = cv2.imread(self.df.path.iloc[index])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        augmented = self.transform(image = image)\n",
    "        image = augmented['image']\n",
    "        \n",
    "        label = self.df.InChI_text.iloc[index]\n",
    "        label = self.tokenizer.text_to_sequence(label)\n",
    "        label_length = len(label)\n",
    "        label_length = torch.LongTensor([label_length])\n",
    "        return image, torch.LongTensor(label), label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b9d6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset) : \n",
    "    def __init__(self, df, transform = None) : \n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) : \n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx) : \n",
    "        path = self.df.path.iloc[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        augmented = self.transform(image = image)\n",
    "        image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34906106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aea8c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TrainDataset(train, tokenizer, get_transforms(data = 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5672b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAFECAYAAAATP6KjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB7HUlEQVR4nO3ddZgcVdbH8e+ZiXsgQpTguiFAcHdZ3DXBFnhx2UWXxWFhcbeQBHcLrsF3IWiwQIAAAWKEELeZ8/5xb5OaTndPz0zP9HTy+zxPP8mU3DolXV2n7q1b5u6IiIiIiIiIlKqyYgcgIiIiIiIiUhdKbEVERERERKSkKbEVERERERGRkqbEVkREREREREqaElsREREREREpaUpsRUREREREpKQpsRUpcWY2xsy2znNaN7Pla7mcWs/bmJhZZzMbZWYt4t9jzGyWmd1d7NhEREREpHaU2IpIwZnZcDM7othxZHEGMNjdZyeG7ezuBycnMrMTzex7M5thZl+a2YpxuJnZ2Wb2o5lNNbMHzKxdYr4eZvakmU02s7FmdnS+gZnZIWZWYWbTE5/N47jmZjbIzH4ws2lm9pGZ7ZA2/xFmNjrO97yZda/55vmzrC3N7MO4jt+Z2ZGJcQPN7IM4bqyZXW5mTfIst0+8SZJcx3MS459LGzfXzEYmxr9mZhPjsj8xs11rsE5XmNk3cft9ZWYD0sbfFm96VJrZIWnjbkmLa46ZTavBsluZ2U1mNsnM/jCzNxLj/mFmn8W4vjezf6TNe6GZjTSz+WZ2Xr7LTMy/ddyXM8zsJzPbJzHO4/DUet2RGLe6mb0QYy7oS+/j8Xy1mf1iZr/HbdO0lmX91czeMrMpZjbOzG43s7aJ8Z+n7bv5ZjasgOuSdfvWoIxX475okhjWx8yejdtnnJndkBpvZqua2Yg47ncze9nMVi3Q+jQzs0cs3PTz1DmoBvNnPV4tyHr+TEy3RPyev1WnlalaZs7vv4iUPiW2IrJYMLMmZtYcGAjcU820RwCHA38F2gA7AZPi6AHAwcBGQHegJXB9YvZ7gO+BrnH+S8xsixqE+q67t0l8hsfhTYCfgM2A9sA5wENm1ifGvBlwCbArsESM4f4aLPdPMcF4HLg1Lmtf4CozWyNO0go4CegErAdsBfy9hovpkFjHC1MD3X2H5PoD7wAPJ+Y7Eejm7u2AI4F7zKxbnsucAewc12kgcK2ZbZgY/wlwDPBh+ozufnRaXPenxVWd2wj7ZZX478mJcUY4rjoC2wPHmdl+ifGjgdOAZ2qwvFBwSHbuA84mrHc/4IO0ydZIrFvyhtQ84CHCd6HQzgD6A6sDKwJrAf+sZVntgYsI38dVgJ7Af1Ij3X21xH5rC/xIzfZdVnlu3+rKOJDw/U53EzAB6BbL3YxwfAL8AuxFOJY6AU8BD9Q0/hzeAg4CxtVi3lzHa3Xnz5TLgC9rsexcqvv+i0ipc3d99NGnhD/AGGDr+P91gXeBKcCvwA1As8S0DpwAfEdI1P4DlCXGH0a4mPgdeAFYOm3e5fOI52KgApgNTAduiMNXBl4CJgOjgH0S8wwBbiRcCE0D/gcsF8cZcDXhAu8P4FNg9TiuPXAXMBH4gXBhXBbHHQK8HeedTLjw3RQYnW37xb/LCAnkVlnW7xHgH4m/N4zr2oqQBDvQOTH+NuDuPPflIcBbNdj3nwJ7xv9fAdyYGNc9xrJcLY6prnHeVolh7wP7Z5n+FGBYnmX3iWU3yXPaCmCZLOPXjdt+3Vp+d54CTs0w/C3gkBzztY7H6WZ5LmclYCrQLs/prwOuzzD8HuC8Gq7jfcCFOcZX+70Glge8Nts4R5kjgL0Tfx8A/FSgsvcARmYZtxnhvNS6QMvKuX3zmL898DWwfvr3gnAu3jHx93+AWzOU0QQ4FphZyH0Uyx4LbF7LeRc6XnOdPxPDNiD8jh1ak/NhLeLL+P3XRx99SvejGluRRUsFoSaoE+HiYCsW3OFP2Z1QU7IWoXbvMAAz2w04i3BR2Bl4kyw1fmZ2gJl9mmmcu58d5z3OQy3JcWbWmpDU3gd0AfYHbjKz1RKz7g+cT6i1Gk1IkAG2JSSkKwIdCLWHv8Vx1xMuDJclXLAOIFwMpaxHSOK7xPL+Qkiqc+kZP6vHZoXfm9n5ZpY6X1r8kPi7ObBCYnj6+NWrWWbSmrHp59dmdo5laeJrZl0J2+TzHHFRw2UD4O7jCfv+UDMrN7MNgKUJCV8mmybiyNcPFpoxDzazTlmmGQC86e7fJwea2dNmNptwA2Q4IUmqETNrCaxDzeMG2JNwM+WN6iaM1iPceDk/7tuRZrZnlrgM2KSWcWWyfix3pJn9amb3mNkSadO8EZu6PpZqAdAAMh2vPc2sfQHKznU8DgQecfcZBVgO5Ld9c7kEuJnMNaPXAvtZaMbeA9gBeD45gZlNISSG18eyGrtc50/MrJxwk/M4QqJfP0HU7fsvIo2UEluRRYi7f+Du/3X3+e4+htCUdLO0yS5z98nu/iNwDSGhBDgKuNTdv3T3+YSLpH5mtnSG5dzn7n1rENpOwBh3Hxxj+xB4lNCULuUxd38vLvteQtM7CM0h2xJqfC3G92u8ANoXONPdp8X1vZLQzC3lF3e/Pi5zFiExru65yJ7x320JifAWhG2Uao75HHBEfP6tPXB6HN7K3acRaonPMbMWZrYWIQlqlc9GIiRKqxMS8T3jcv+RPlFsKnwvMNTdv4qDnwX2MbO+8aLtX8Ra1zyXne7+WMYcwo2Ks939pwyxHEq4UXJFnuVOIlxQLg2sTdi392aZdgChNr8Kd98pzrcj8IK7V+a57KRbCE2PX6jFvAOBu9w93wvvnoT9+gehJv04YKiZrZJh2vMIv82DaxFXtmUfTDieVmDhpp+bEWrGVyY0b306282UAnsOONFCZ25LEVqSQO2PVwDMbBvC/vlXhnGtCOecIXVZRprqtm9WZtaf0CQ32/SvA6sRavvHEm7gPJGcwN07EG7uHQd8VNPgiyDr+TP+ewLwP3evUXPuWqjL919EGikltiKLEDNbMdZmjTOzqYTkNL02LJmc/EC40IaQaFxroQOWKYTmuwb0KEBoSwPrpcqO5R8ILJWYJlljMZPQrBd3f5XQpPpGYLyFDn7axfVqFtchuT7JeNMTsd8JCVEus+K/l7v7lMQNgh3j8DsJSd9wwt3+1+LwsfHfA4Fl4rJvJiRtqXE5uft37v69u1e6+0jgAqom/8Sa47uBuYSL2dS8rwDnEm4Y/EBoYj0t32WnLWNl4EFCYtmMcHF9mpn9NW263YB/Azu4+6T0crKs43R3HxFvNoyP67BtegcyZrYx4fh4JEs589z9OWA7M9ulhuv3H0KiuU8NktPUvL0IyeBdNZhtFuEGzUXuPtfdXyccN9umlX0cYZv/1d3n1CSuapY92N2/dvfphHNC6ljG3d+IMU0hPL+8DOE51fp2MSER+5jwHPUThG00obYFmtn6hFYhe7n71xkm2YNwXnu9tsvIIOf2zRFrGeEZ2hPjzbxM418AHiM0fe9EaM1yWfq0sfb5FuAuM+tSh3VpCFnPnxY6uzuB8LxyvanL919EGjcltiKLlpuBr4AVPHSucxZVm30B9Er8vzehlgZCInaUu3dIfFq6+zu1iCP9YuEn4PW0stu4+//lVZj7de6+NiHBWpFQizmJcCGcrFHuDfycI45P4/y5jCIkjRkveGLSea6793H3noSLs59Ty3X3H9x9J3fv7O7rAUsC7+WxmhkXR2L/xWaqgwjPwO7p7vPSYrvR3Vdw9y6EBLcJ8Fktlrs6MMrdX4jrO4rw/POfvTCb2fbA7YQepUdmKScfqe2cfpwOJNTiT69m/ibAcvkuzMzOJ6zHtu4+Ne8oFxgAvOPu39VgnozN9tPiOozQodJW7l7jmxHVLLsmF+9Vjrn64u6z3P04d+/h7ssSHi/4wN0ralOema1JeGbysHiTJ5Oa1rTno6bbN6UdoaXDg2Y2jvAMO4QEbxNCp1C9CH0UzHH33wi1+NmS5jJCrWchbkTWm2rOn+sSOsr6Im6Ta4F1443a8kIsvwDffxFpxJTYiixa2hKarU2PtW6ZEsd/mFnHWPN0IqFmDsId/zNTz72aWXsz27uWcYwnPPea8jSwopkdbGZN42edLE0xq4jTrReb384gPE9WES+AHwIuNrO2scn0KeTu8fg9oEN8Xi0jd59J2CanxXJ7An+L65B6DcVyFqwKXAVckGoOa2arxPmamdlBhFq5qxLrM8bSXiWTGLdDfHY2VWt6DvBkYpKbCbVpO8em1cl5W1h4PYuZWW9Cp1XXuvvvcfwhZjYmx7ZJ+ghYwcIrf8zMliM0J/8klrUloSZ6T3dfKGk3syFmNiTLOq5nZiuZWZmZLUnoKGm4u/+RmKYlsDdpTUbNbOW4jVrGY+ggwvOUr8fxqVcJ9cmy7DMJnRRtExOF9PHNLLzf2ICmcZum/05mbB6da50JTcx/JHy/mpjZRsDmxGaQFnrFvSTGtVDCHNe1BeE3u0mMqzyfdSYkQ4ea2bIWmuKezoJjeTUz62fhOeo2hKb8PxN7o437vgWh1j51jDXPc51zsvBarO5xGesTjvVza1O2ma1OePb0eHfP+Bqf+D3eAhiaYVzW72Qesm7faspONUvvFz+phHVtQlPcSYSezf8vHjMdCIl56ju4jZmtGfddO8I55ncW7LuafN8XYuF1TC3in83ivrd8yq7meM11/nyO0Cw+tU3+RTgX9Uvd8KjLvsrj+1+X40BEGgNvBD1Y6aOPPrX/ULVX5E0JNbbTCc9FXkCiV0mq9or8G+FCtjwx/mBgJCE5/gm4M23e5eP/DwQ+zxHTBoSePn8HrovDViLU+k2My36VcMECIVG4KDH/5sDY+P+tCLUi0wm1tPcCbeK4joREdmKM919U7RV5oR41CT2Lnp5p+yWGtSO8OmNaolyL41Yk1OrOJDT5PSVt3pNiPDMInS31T4xrFstcOct2u4JwU2BG3EcXAE3juKXjPkj1Np36HBjHd4jbaQahWfelafv2HODeGhxX+xBqe1PNmS9LbNvXgPlpcTyXmPcV4G9Zyt2fcME+g9Bz913AUhmm+SG1zRPDVyF0GDWN0PP3+8DuifGbxP3ZNMuynfDMcDLusxLjh8dpkp/N047rGUDbDGVnXec4fjVCT68zgC/S4v6e0PogGdctifFDMsR1SD7rHKc5Px6TEwnN2DvG4VsSjuUZhCbATxBae6Tm65NhuWPyXedqjq9NY9wzYwwH1mR7pk07GKhM236fp01zJqEjsvR5c34n81x+tu2bd9lk6C2ckNwNJ5xHJxFeUdQljtubBef6iYRn7PvW9vueIZ4xGfZ9n3zKruZ4zXn+TCvnEKr+ftVpX5Hj+1+I40AfffQp/id1oSYislgws1SPz2u6+ywzG0Vo/va4uw+s52VvDBzr7vtXO3Hhl/0i4Xm+Qr8bMn05zQi1Sn09ral0fTOzfwIT3f3WBl6u1rlEys6wrHr7Ti6q3/eGOpdkWO4iua9EpHCU2IqIiIiIiEhJ0zO2IiIiIiIiUtKU2IqIiIiIiEhJU2IrIiIiIiIiJU2JrYiIiIiIiJQ0JbYissgysxXMbLaZ3ZMYlnrv5/TE55zE+A5mNtTMJsTPeQWOaS0zeyMud7yZnZjnfN3M7Ckz+yXTe0vNbB8ze8fMZprZ8Azzu5nNSKzzHYVZI4jv0rwoxjbNzD6K792sTVn9zOxNM/vDzMaa2b8S4/5qZm+Z2RQzG2dmt5tZ2wKuR2czuy+W/7uZ3VuLMgbGbX1EYtjqZvaCmU0yM0+bvrmZDTKzHxLbbodCrE9iGfuZ2Zdx/39rZpvkOd9JZvadmU2N+/ZqM2uSGJ91X6WVMzhuk+ULuE513lexnPXN7CUzm2xmE83sYTPrlhjf3Mxuid/VyWY2zHK8B7uGy97CzF6L229MLeYdGdf/NzN7PBlXHueDfmb2QRz/gZn1q/MKhXJXNLMn47acHI/7lQpRtohIdZTYisii7EbCu04z6eDubeLnwsTwq4FWhPdKrgscbGaHFiIYM+sEPA/cCiwJLA+8mOfslXHePbOMnwxcA/w7RxlrJNb5iBzT1dT5wIaE97y2I7wPeXYty7oPeANYAtgM+D8z2yWOaw9cBHQnvNO2J+G9xIXyGOEdwEsDXQjvFc6bmXUkvC/187RR84CHgMMzzNaE8K7kzQjrdw7wUPqNi9oys20I7yA+FGhLeH/sd3nOPgxYy93bAasDaxDeg52Sa1+llr8xsFxd1iGLOu2rhI7AbYTv+9KEd5kOTow/kXBc9yUcd1OA62u5rHQzgDuBf9Ri3i+A7dy9Q4zrG+DmxPis5wMLr1N6kvAO8I7AUODJOLyuOgBPEd5b3hV4Ly5LRKTeNal+EhGR0mNm+xEuQt8hJJD52hnYwd1nAmPMbBBwGFUvdmvrFOAFd0/VLs0B8noXpLuPB25K1piljX8ZIFlT2BBiMncSIWn+IQ7+rA5F9gHudfcK4FszewtYDXjK3e9LTDfTzG4nJNV1ZmbbAr2AzeOyAT6qYTGXAtcB+yQHuvsoYFSmGkt3nwGclxj0tJl9D6wNjKnh8jM5H7jA3f8b//453xnd/dvEn0a4uZJchz5k2VcA8Vi9HhhIeC9tQRRoXwHg7s+llX0D8Hpi0DKE7+z4OP4B4KraLCvDst8D3jOzrWsx7/i0QRUk9k0154PNCdd/13h45+N1ZvZ3YEvCzbNaS61T6m8zuxr4p5kt6e6/1aVsEZHqqMZWRBY5ZtYOuAA4NcdkP8Tmk4NjTWqVItL+v3qBQlsfmBybCE6IzRp7F6jsfLwRm/A+VqgaQeAvwHxgr1j212Z2bB3KuwYYYGZNYxPGDYCXs0y7KQvXjtbW+sAoYGhs2vm+mW2W78xmti7QH7ilLkGYWVdgRQqwXmZWHmPqbGaj4/F+g5m1rEEZB5jZVGASocb21sToa8i9r04G3nD3T+u6LmnqtK+qkX5MDQI2MrPuZtYKOBB4LuOcDczMepvZFGAW8Hfg8jxnXQ34NCa1KZ/G4YW2KTBOSa2INAQltiKyKLoQGOTuP2UYNwlYh9DscG1C88zk83nPA2eYWdtYw3YYoWlyIfQk1F6dCPQGvgfuL1DZ1dmMUMO2MvALoWawEK12ehKa0K5IqN3aCzgvNoGtjadjGbOArwj7caHm5LH8gUDG5zproSewLfAasBRwJaF5ZvpNj4XEBPIm4Hh3r6xtAGbWlHAsDnX3r2pbTkJXoClhe24C9APWBP6ZbwHufl9sirwiIWlP1hRm3Vdm1gs4isLtn6Ra76tczKwvId5k0+CvgR8JNd1TCU3gL6jLcgrF3X+MTZE7EfZpvsdMG+CPtGF/EM6FBWNmPQmPg5xSyHJFRLJRYisii5TYCcrWhGdlF+Lu0919hLvPj835jgO2jbW8EJ4hnEV4Zu1JQuI5tkDhzQIed/f33X028dlUM2tfoPKzcvc33H2uu08hJNbLEC7S62pW/PcCd58Va+ceAHasaUFmtgThxsIFQAtCc9PtzOyYtOnWJzzfuZe7f12X4BNmAWPcfZC7z3P3BwjPvm6Ux7zHEGrA3q3tws2sDLgbmEs4JgshtW+ud/df3X0SoRltjfeNu39DqMm8CfLaV9cQjon0BKoQ6rKvMoo3sZ4DTnT3NxOjbias35JAa8KzvY2ixjbF3Sez4DnZfG5WTSc8C5/UjvB8cUGYWWdC/wE3uXtD3bwTkcWcElsRWdRsTqiZ/NHMxhGa6O1pZh9mmT7VHM8gXCS6+4HuvpS7r0Y4T76XZd6a+jSxvIWW3cC8QMtNNTP1nFPlZ1mgwt3vijcexpKWJJvZmoRnOA9z91cKsMyU9H1TE1sBu8em2OMIHWldGZ/XrJaZGaHJa1dgT3efV8s4qnD33wk3ZQqxbyA8l5nqCKq6fbUV8J/ENgF418wOKEAcddlXCzGzpQlNqC9097vTRq8BDInnhTmEZ4bXrWvtcD1oQuhEKz1hzeRzoG887lL6UqBm/fG5+xcJz8VfXIgyRUTyocRWRBY1txEuvvvFzy3AM8B2AGa2npmtZGZlZrYkobOf4amaJTNbzsyWtPAKmx2AIwk98RLHD7favwJoMCEB6hebnZ4DvBVrUast28xaAM3jn83j36lx5fHvJkCZmbWIy8DMVovLLDezNoSmmz8TO64ys80t7TU0+YodDL0JnG3h1SirAPsSmqnWtOyvwyx2QNw/S8WyPollrU6oJTze3Yelz2xm51mGV5vk6XGgo4XX9ZSb2V5AD+DtPMo+hFD73S9+RhBq48+O81rcN83i3y3MrHli/pvj/Du7+yzSWHhVzua1XK/BwPFm1sUWdPT1dD5lm9kRZtYl/n9VQo/PqZsJOfcVoenyGizYJhA6Zns8llesfZW+jj2AV4Eb3T3T89HvE54jbh+/T8cAv8Ta7zqdD+J2a0FoLm7xuGiWGJ+1bDPbI3Ee60yoif8o1t7mPB8AwwmdTZ0Qv7OpFgKvxnlrfT6ILV9eAN529zMyjK912SIi1VFiKyKLFHef6e7jUh9Cs7vZ7j4xTrIsITmaRui9dw6wf6KItYGRcfylwIHunqzJ6EW8gK5FbK8CZxES7QmEXkyTNVjVlT0rrg+E5+mSSdDB8e+bCc9TzgJuj+O6Ag8SnhH8jlCjvVOiZrAXUOtmtITttzTwG2HdzknUpuZdtrtPBfYgdDr0O/AxYR+lan1OBToDg2zB+3gLtW8mA7sQavj/AM4Adk0lMLnKdvcpacfcXGBqohnu0oT9kYp1FqHzo1Rt4VGE5G9cYr0OjON7Evb5yNqsF+F58/cJieiXhN6DL86z7I2AkWY2A3g2fs6K65xzX7n7hLRtAjApkbgXZV9lcAThnHBuYttPT4z/O+HVVd8AEwk10rsnxtd6PQgdK80ibNfe8f/J13/lKrsHC85jIwk9Vifjyno+cPe5wG7AAELP8YcBu8XhqeXW9nywO6EPg0Ot6rvCU53k1fVcIyKSlVXtFE9ERLKJicDD7r5BKZWdx7LviMt+oZTKzrCsj4Gt6qMH1vosu5rlHgSs5u5nllLZeSz7Y0p8X+l80LjKFhFRYisiIiIiIiIlTU2RRUREREREpKQpsRUREREREZGSpsRWRERERERESpoSWxERERERESlpSmxFZJFnZiuY2WwzuycxbFUzG2Fmv8fPy/FdnanxHcxsqJlNiJ/zChzTWmb2RnwVxngzO7EOZS1rZk+b2TQzm2RmlyfG3WNmv5rZVDP72syOKMwagJkdF7fhHDMbUseyljCzB2P8k8zs3vhOTMxsRTN70swmmtlkM3vBzFYq0DrUS9lmtpmFd8Qm34G8uZlVpr0GZWBdlxXL7mZmT5nZL3G5fWowbycze9vMfjOzKWb2rpltlGXaV2P5TRLDpqd9Kszs+gKsU3MzG2RmP8Rj+yML75aubXk94r6ebGZjzezotPFbmtmH8bvynZkdWYdlXWhmI81sfqZzh4X3//5gZjPM7AkzWyLPcnPuKwsuMrOfzewPC+/CXS1DOQudEwvBzPYzsy/jen1rZpsUsnwRkVyU2IrI4uBGwrs8k34B9gKWADoBTwEPJMZfDbQivPN1XeBgMzu0EMGYWSfCOyhvBZYkvM/2xZwzZS+rGfAS8CqwFNATSF6sXgr0cfd2hHd/XmRma9c++ip+AS4C7ixAWRcBHQnvFF2O8O7d8+K4DoT9s1Ic/h7wZAGWWS9lm1lT4FrgfxlG/+LubRKfoXVZVkIl4ZjasxbzTie8y7QzYR9cBgxLJq8AFt6t2yR95uT6ELbhLODhWsSRrgnwE7AZ0B44B3ioJkl7mnuA72OMfwUuMbMt4M999jjhO9ke2Be4yszWqOWyRgOnEd7rXEVMNG8lvGu2KzATuCnPcqvbV3vH8ZsQzm3vAndnKCfTObFOzGybGM+hQFvCe3q/K+QyRERyUWIrIos0M9sPmAK8khzu7lPcfYyHd54ZUEFIMFN2Bi5395nuPgYYRLhgLIRTgBfc/V53n+Pu09z9y1qWdQghWbrK3We4+2x3/zQ10t0/d/c5qT/jZ7k6Rb+g7Mfc/QmgEO8LXQZ4wt2nuvsfhCRjtbic99x9kLtPdvd5hJsOK5nZknVdaD2VfSrhRsVXdY0vX+4+3t1vohbJSjxmRrl7JQu+Cx0JiREAZtYeOJeQrOWyFzABeLOmcWSIa4a7nxe/p5Xu/jQhMa3xjRkzawNsDlzs7vPc/RPgERZ8p5cA2gF3e/A+8CWwaqby8oh9qLs/B0zLMPpAYJi7v+Hu0wkJ+x5m1jaPcqvbV8sAb7n7d+5eQUjmq6xDtnNiAZwPXODu/43762d3/7nAyxARyUqJrYgssmJT1gsIiUa2aaYAs4HrgUvSR6f9f/UChbY+MNnM3rHQzHmYmfWuQ1ljzOy52IR3uJn9JTmBmd1kZjMJidavwLN1C79e3AjsZGYdzawjoebxuSzTbgqMc/dCJNQFLdvMliYkSxdkmaSLhabn35vZ1WbWuraBFpqZfUr4LjwF3OHuExKjLwFuBsZVU8xA4K54w6jQ8XUFVgQ+r83saf+m/r86hBsDwP3AoWZWbmYbAEsDb9U+4qxWAz5J/eHu3wJzCeuWlxz76gFgeQtN7JsS9sfzifmqPSfWhpmVA/2BzmY2Ojb1vsHMWhZyOSIiuSixFZFF2YXAIHf/KdsE7t6B0PTwOOCjxKjngTPMrK2ZLU9IVloVKK6ehAvOE4HehFqo++tQ1n7AdUB3QtPHJ2MTZQDc/RhC08BNgMeAORnKKbYPgWaE2t/fCDVRCzXPNLOehCT4lEIHUKCyrwPOiTVx6b4C+gHdgC0JNY9X1WFZBeXufQm1lgeQSOjMrD+wEeHmT1bx5sxmQKGaVyfLbgrcCwx19xrXhLv7NOBt4Bwza2FmaxFuniS/0/cD/yJ8P94Ezs517qiDNsAfacP+IHxH85JtXxFuXL0JjCI0Cd8bODkxvtpzYi11BZoSauw3IRznawL/LPByRESyUmIrIoskM+sHbE1oWpqTu88AbgHuMrMucfAJhAvDbwjPXN4PjC1QeLOAx939fXefTWjCt2Fs7lmbst5y9+fcfS5wBeG53VWSE7l7hbu/RUiE/69u4deLh4GvCRf37YBvqfqsMGbWmdDE9yZ3r+2NgIwKUbaZ7Qy0dfcHM41393Hu/kVspvk9oVnvXrUOuh7Epq73E27qrGFmZYQbDCe6+/xqZh9AOBa/L2RMMYa7CbWax9WhqAMJTXV/ItQ+30v8TpvZysCDhHVoRqhVPc3M/lqH5WUznXCMJ7Ujc7PlrNL3VRx8LrAO0AtoQTi3vGpmrWpyTqyFWfHf6939V3efRLhps2M9LEtEJKOFOoEQEVlEbE7o+OlHM4NQS1JuZqu6+1oZpi8j1N70ACa4+2TChTAAZnYJoWOhQviU8KxrSur/lmHafMrK2INtFk0o0DO2BbYGcEy8yYCZ3ULVWsOOhMTzKXe/uJALLmDZWwH9zSzVXLc9UGFmf3H3XTNMn3q+uzFqSujI6wdCE9MH4/eoPI4fa2Z7u3vyWdoBwL8LGYSFhQ4i1AjuGJ+DrhV3/wHYKVH2fSz4Tq8OjHL3F+Lfo8zsGWAHMnQAVUefE473VBzLAs0JN3ZqI7WvPonlPujuqZtwQ8zsGsJzthtTs3Ni3tz9dzMbS9XzmohIg1KNrYgsqm4jJHD94ucWwgXqdhB68DSzNePzdO0ItQu/EzqMwcyWM7Ml4/gdgCMJPfcSxw+32r8CaDCwu5n1i00szyHUdE2pRdn3AOub2dbxObeTgEnAl2bWJb5+o01cj+2A/Qk9KKfWw81s89qshJk1MbMWhGSnPDbxTL4GpiZlvw8cYWYt43N5RxKfQ4z75wXgbXc/I0Mcm5tZrS6oC1z2OYTnJPvFz1PA7YReYlNl9bagFyEJ/LMHZjM7z8yG12Y94vwtCAkSQPP4d7Vlm9n6ZraxmTWL2/90QiL5P0IT2e6JdUrVwK1NotdnM9uQcFNood6Q63KMEWpWVwF2dvdZ6SNrUraZrRIfLWhmZgcB27KgKfhHwAoWXvljZrYcIQlOHYM1OsbMrGnc/mVAk/jdSN0UuBfY2cw2sfCM9QXAY7G5dF32FYTv0d5m1tXMyszsYELiO5pqzomx/Lrsq8HA8fG805FwLnq6QGWLiFRLNbYiskhy95mE12gA4V2bwGx3nxgHdSA8M9iT0IzufWD72DQYwoX7NXG6r4ED3T3ZaU0vwjN7tYntVTM7i3BR2YpQM3lAbcp291HxIv0WoAvhWdVd3H1uvBD/vziujFD7dpK7Pwl/PlM6HRhZm/UgPD93buLvgwhNH8+rRdmHEZ5PHUuoxXyP0OMzwO6E5pWrmdkhiXlWdfcfCdvr3dqtQuHKjonJn81JzWwWMCPW/gOsRUhqOhKeI34COCtRRK2PqSiZ+KWeQ03VCOcquzlh2y8LzCPss7+6+y9x/J8dRiWS5fFpTZMHkkjOEtPX+hiz0BHXUYRnXsfFWkaAo9z93lqUvR1wNuE79xHh+z4RQgdOZpY6BpcmJPT3EmqLoebH2O2EbZJyNuEGxxB3/9zCO3TvJTw28HIcl1KXfXUZ4TzwMdCakNDumbppRo5zYgHOBxcSXp32NaFjq4eAiwtUtohItaweOi4UEVmkxYu0h919g1IqO8OyDgJWc/czS6nsDMu6g7DNXqh24kZUdoZlfQxsVR+9Pddn2dUsV8dYzZf1MdpXIiI1psRWRERERERESpqesRUREREREZGSpsRWRERERERESpoSWxERERERESlpSmxFRERERESkpCmxFZGSZ2YrmNlsM7snMWxVMxthZr/Hz8tmtmpifAczG2pmE+LnvALGc56ZzTOz6YnPsrUoZ3B89+PyiWFLmNmDZjYpfu6N72LFzDqZ2dtm9puZTTGzd81sowKul5vZjMQ63VGAMjeL5SbfEby5mVWmbb+BucqpwfIKWraZHWFmo2M5z5tZ98S45mZ2i5mNN7PJZjbMzHoUIk4z+zxt3HwzGxbHNfrjIMt3tk8sO7le5yTG1/o7W8ztaWbHxXPRHDMbkmF81mMoMU0zM/vKzMbmu9w84irIeSqWNdDMPjCzqWY21swut6rvtJ6e9qkws+sLtS4iIqD32IrIouFGwntok34B9iK8u7UMOBZ4AOgbx19NeJ9lH8J7H18xsx/cfXCBYnrQ3Q+q7cxmtjGwXIZRFxHeg7os4R2ljwLnAacQ3hN5GPAN4MCuwDAz65L2ztG6WMPdRxeiIDNrClwL/C/D6F/cvWchllNfZZvZZsAlwBaEbX4tcD+wWZzkRGADwjH3B+HdptcDe9Q1TndfLRGHAd8CD8dBpXAcZPrOpnTIEmddv7PF2p6/EL632wEtkyPyOIZS/gFMANrksbyaqNN5KqEVcBLhu9wZeAr4O/BvAHf/M24zaw2MZ8H2FREpCNXYikhJM7P9gCnAK8nh7j7F3cd4eKeZARXA8olJdgYud/eZ7j4GGES4eC26WNNxPXBchtHLAE+4+1R3/wN4HFgNwN1nu/sod69kwTp3BJZomMhr7FTgReCrYgdSSzsT3m36ubvPBS4ENjWz1A2JZYAX3H28u88m3FhZLUtZdbEpIdF7FBr/cZDtO5uHhvrOFnR7uvtj7v4EkOm9tNUdQ5jZMsBBwKW1X6X65e43u/ub7j7X3X8G7gWy1WrvRUjS32ywAEVksaDEVkRKloUmuBcQEqRs00wBZhMSxUvSR6f9f/UChrdzbH76uZn9Xw3nPRl4w90/zTDuRmAnM+toZh2BPYHnkhOY2aeEdX4KuMPdJ9Qi/mzeMLNxZvaYmfWpbSFmtjQhKbkgyyRdYhPe783s6ljLUyiFKttY+BiCBcfRIGAjM+tuZq2AA0nbVwWKcyDwiLvPqBJcIzwO8vnOAj/E5qyDzaxTehFp/6/Jd7Yxbs/qjiEI566zgFkFWF66upynctkU+DzLuIHAXfGmo4hIwSixFZFSdiEwyN1/yjaBu3cA2hNqPz9KjHoeOMPM2lp4hvUwQnO6QngIWIXQJO9vwL/MbP98ZjSzXsBRwL+yTPIh0IxQ+/MbofbopuQE7t4XaAccALxVi/iz2YzQDHRlQvPKp5PP0dXQdcA57j49w7ivgH5AN2BLYG3gqloupz7LfhbYx8z6mllLwj5zFhxHXwM/Aj8DUwnHRLZEvlZxxoR5L2BI+rhGehzk+s5OAtYBliasb1tCzV9KXb6zjXV75jyGzGx3oIm7P16g5SXV+jyVi5kdCvQHrsgwrjfh+Bla1+WIiKRTYisiJcnM+gFbE567yynWvNwC3GVmXeLgEwg1IN8ATxKeaytIxyzu/oW7/+LuFe7+DuG5ub3ynP0a4ILYzDiThwkJU1vCRfa3wD3pE8Xmk/cTEoE1aroOmbj7G7Gp4RTC86PLEC6Ma8TMdgbauvuDWZYzLm7DSnf/HjiN/LdfToUs291fAc4lNFn9ARgDTGPBcXQz0AJYEmgNPEaeNbY1iHMPYDLwepZyGs1xUN131t2nu/sId5/v7uMJN6O2jbW8UIfvbGPdnrmOoVijfDlwfF2Xk2XZdTlPZWRmuxGeq93B3SdlmGQA8FbcByIiBaXEVkRK1eaEWqMfzWwcoaOSPc3swyzTlxFqQXoAuPtkdz/Q3ZeKHceUAe/VU6yp53zzsRXwn9jMc1wc9q6ZHRD/vwZwq7vPiLWdtwA75iivKaGjqfpQk/VK2gron1jHfYGTzOzJAi8nH3Uq291vdPcV3D31TGYT4LM4eg1gSDzW5hCalK6boXltXeLMt1lnYzgONqdm39nUOhkU/DvbaLZnjmNoBcL2ejNur8eAbvF706cQy04PhTp8F8xse0IHaTu7+8gskw1AtbUiUl/cXR999NGn5D6EJHWpxOcK4BGgcxy/DbAmUE6o2byO0GyyRRy/HKEmrRzYgdAMcrVE+cOB82oZ266EzmUMWJfQFHVgPmUTOq1JrpcD6wMt4/jXCAlSy/i5CXg7jlsf2JjQVLklcDqh9qd7HL95OO3Xap1WIzTlLCf0zHoNMApoWtOyCbXNyXV8kFCLt0SirN5x+/WK6zw4Mf95wPBarkfByibUxq4ey+od9+slifGDCYlKe0IidBbwc57HQc444zQ9gfnAcmnDG+VxQPXf2fWAlQgJ65LxuHgtMX+tv7PF3J6ERLUFofOnu+P/m1R3DMX5kttrD8I5bCmgvLp1zmNf1vo8laGsLQmPRmyaY5oNgRmE1hrp4xzYvDbroY8++uiT+qjGVkRKkoeeUcelPoRXcsx294lxkg6Epop/EJrrLg9s76F3WgjP2I0kXKBeChzo7snOTnoBb9cyvP2A0bHsu4DL3D1ZS5G1bHefkLZeAJPcPdVxzGGEWpyxhAvRZYFD4rjmhM6lfovjdgT+6u6/JJb7bi3XqSsh0ZgKfBdj2Mnd59W0bHeflraOs4AZ7j45TrJWLGsG8A6h9uqERBF12TeFLLsFcB/h2HsvlntOYvzfCZ0NfQNMJOyP3fNcVnVxAhwMvOvu36YNb5THQR7f2WUJz9FOI6zvHCD5zGddvrPF3J7/JBzjZxB6N54Vh0GOY8hDk+zk9poMVMa/K/JY5+rU+jyVwTmEGzjPJt5Vm97sfiDwmLtPSw40s56E9c9WyysikhdzV6d0IiJJ8ULrYXffoJTKzmPZd8Rlv1BKZWdY1sfAVu6e6fUpjbbstOXoOCjschfJ7VnNcheJ85SZHUSoeT+zvpclIos2JbYiIiIiIiJS0tQUWUREREREREqaElsREREREREpaUpsRUREREREpKQpsZWSZmaHx94X3cyWj8Mei+/TEyl5ZnapmZ2U57RXmdnR9RySZGFmq5rZiDyn7Wtm79R3TNXE0NnMRplZiwKUdYKZ/bsQcSXK3NbMnshz2l3M7IFCLj+t/PPM7J76Kl9kUWBmfeL1WJM8pt3czMbWcjl5zWtmY8xs69osoy5qsh1KjZk1N7MvzGyp+PdwM5ttZm8UqPzzzWxGcvuZ2Xtmtlo+85d0Ymtm5WZ2kZn9YmbTzOwjM+uQ57z3mNmvZjbVzL42syOyTHdu3LhbJ4Y9l+jOfrqZzTWzvLqpj1/GyrT5BybGf542br6ZDYvjOpnZ22b2m5lNMbN3zWyjfJZb3TqbWTMzeySeBNzMNk+b18zssrjs38zscjPL60XuZnZW2jrNitugUxzf3MzujHGNM7NT0ubvZ2YfmNnM+G+/1Dh3H+TubdIW+W/g4hpsl0PM7K18p2+oshoTM9vOzN6I37OJZva6me0Sx3Uzs6fi99DNrE/avJeb2U9x//5gZmcnxmU8+ZvZEDO7KP5/RTN7Mi53spm9YGYrpU1/cjx2/ojHUvO08YeY2ch4DI0zs5uT5woz6xDnGxfX8WszOz2tjA2tmkTEzFaP8U0ys2p75ovH/tVx2/1uZjeZWdPE+M7AAODW+Pf6ZvZS3A4TzexhM+uWKPI/wNlm1ixRRj8zezNum7Fm9q9qYrowbqv5ZnZe2ric568MZdX62MhR5tZm9qGFH76fzGyfHNMOsXB+TsZbnmP6fczsnXicDM8wPuu5KLqQ8G7W1PRZz7nu/ikwxcx2Tkxfo98WM9vCzF6L+3ZM2rguZnZ/3PZ/WPjtWC+tiDMI73KdXd36W/W/P7cBB5lZl8Q8x5nZCDObY2ZD0srL+ZsTXUI4n6ev92ZxnotSw9z9KWB1M+ubmC7n/kxMNzCWt9B1gJm9aGbbZps3MV3q4i6170ZVM/30tE+FmV2fZdqc54kM099m4YZFpZkdkjaupueorGWlTfeqpZ3LLUNSYdX8RprZlvH7PdXMvjOzIxPjMt5csKo3tgfG7+ZUC+e7yy1HcpHv+mWYb6FjJs/49ovL+8PMJpjZUDNrl+9ypXHKdKzXsbw/r4EaoSOBNxKvIwQ4zt03TU4Uj/UvLfxWf2tmm8ThOc/97n4u4X3pSVcAF+QTXEkntsD5hBd+bwC0I7yDbnbOORa4FOjj7u2AXYCLzGzt5ARmthywF/Brcri77+DubVIfwjvxHq5B3L8k50++N87dV0uU2xb4MVH2dMI7LDsTXqp+GTAs10m7huv8FuEde+MyzHsksBuwBtAX2Ak4Kp+FuvsladvrMmC4u0+Kk5wHrAAsDWwBnGaxxtXCBfqTwD1xnYcCT1riwj3D8t4D2plZ/3zia8zMrGuxyzazvQjH4F1AT8J7LP8FpC7IKwnvntwzSxGDgJXjcbchcICZ7VGDUDsATwErxWW/RzgmUvFtR7hA34rwTs1lCeeG1PhTCcfcPwjvWVyfcKy9lDiOrgbaAKvEaXYhvPs2aUfg2WpinQc8BBye57qdAfQHVgdWJLxr85+J8YcAzybeYduRkED0ieswDRicmtjdfwW+ivGn3Ae8ASwBbAb8n8WbElmMBk4DnskyPuv5K4OCHhtmtmpcn7MJ+6kf8EGO5QNcnhZvRY5pJwPXkDmZynkusnCDYQvgicRs1Z1z7yVxHq3Fb8sM4E7CsZ2uDfA+4d2vS8R4nzGzNjHe5oT3iiYvxLOuP9X8/sTk+DnCjZiUX4CLYoyZZP3NMbN1gPbu/t+04U2Ba4H/ZSjvfsJvVT7rkyqvI3Am8HmGca0J2+/1bPOnOS6x/1bKNWHafu5KeLdttn1d3Xki3SfAMcCHGcbV9ByVqywAzOxAoM41U3HfPk64kdce2Be4yszWqEExrYCTgE7AeoTfhb/nmL7a9csQZ9ZjJg9vAxu5e3vCb1UTwnckn+XW2/VAQ5QvpS2RaxwF3F3NtNsQfiMOJeQymxLee56SK9/I5ClgC6t6Iz8zdy/JD+GHdTqwXAHKWomQvO6TNvw5wsXsGGDrLPP2ASqAZfJc1ubA2Dyn3SyuY+sM48oIiYUDXQq1znHcWGDztGHvAEcm/j4c+G8tlmuEhGFgYtjPwLaJvy8EHoj/3zaOt8T4H4Ht08p1YPnE37cD5+YRzyqEmyEVcVtPicObE+4Q/QiMB24BWsZxzwJXJsp4kHDhlrGsWmyjVoQv/KvAF4nhhxBODNOA74EDE8fCP4EfgAmEBLR9HNeCcOH6GzCFcKHbNY67GfiCcFG8VI799SPwjzzibhL3Q58c0/QARgKnJb4/DjRJm24IcFGWMpaI8ywZ/74PuCQxfitgXPx/u7gv0r/bbeK2Oiz+/RmwWzXr9yGwVvz/asBLhAvn8cBZadMuD3ge22wEsHfi7wOAnxJ/vwoclGP+tYBpacPOJtTCpf6eCaya+Pth4Mw8YrsHOC9t2Obkef6q67GRZZr7gAtrsNysx1E18x1BuPmWHJbzXERI6F7OUeZC59y4zrOA5hmm70Oevy3A1sCYPKabCqwd/78pMDrf9U8bn/H3BzgQeC3D9BcBQ3KUl+k351/AHRmmPQO4PNO+BTYCvq/J+hDO7ccAw4Ej0sbtAjwV/38eISG8i3AO/hzon5h2oflrcLwNJJzbLcv4nOeJHOW+BRySZVxe56jqyiIkoF8TbhhWOZeT4dqJ8Dv2VpZldI1ltEoMex/YP7EP7skwX5Xf/7RxpwDD6rKt8j1mahof4XfoLsLNy2zL6gD8H+GG7nOJ4d2BR4GJhOuBExLjmhNu6PwSP9cQzzGEhP9pwvXAZOBNoCyOey4u5/+ADrU8lvskjwNCYvNl/M58BxyVmHZzwnf/LGBSPF4OTFuPbNdhm5PHb1HyGCSct84gXIP+Rvg+L5EW98C4vEnA2YlyWhJuDv4e1+e01PIJSV4l4Vw+PY7LWV41MR9JuAE1N5Y3LI99fh65z0+nE36/pgGjCO9qr+5YSe2f0wkJ6N1A77ieye/5cBY+d74DHJ7Hui507s90HMVhL5HIHbJ9SrnG9i/AfGAvC80HvzazY2tSQGzOM5NQw/EridoYM9sbmOvu1dXQDADedPfva7DoLmY23sy+j82LWmeZbiDwiLvPSIv7U0IC9RThh39CvgvOtc7VWI1wZzPlExZuKpCPTQg/Xo/GeDoSvqzZyl4N+NTjUR19mseyvyTULufk7l8CRwPverh73iGOuoxwZ7wf4QKgB+FCC0KtxcGxydSBwDrAidnKMrMD4j7Lycw2MLPbCCefgYRkee04rjVwHbCDu7cl1G59HGc9JH62INwBbgPcEMcNJFx49AKWjPGlav+OBU4g1MCPMrNhZraHVW3itlKc95Hq4q9m3c4ws+mEk1hrQoJSW5sSEtff4t+Zjs2uZrYkYTu1AB5LFuDu0wk/4tvEQf8FLjazQ81shQzxdyMctx+ZWVvgZUJNZHfC8fFKLdfF4if5d08zax///gvhRyibTVm41iD92L8GGGBmTS004d4gxl9b+Z6/8lLDY2P9OM9IC0187zGzJapZxDEWmm5/YGbZao7zUd25KOO+ynXOdfefCRcwmWr3avPbkpWFZtPNCDXyWePNo5xcvz95nXfztFB8ZrY04fybrUnal0CffJt2mtm6hJrQW7JMsiNVWy7sAjzAglYkN6RNf6mFJr5vpzevq8ZA4K60Y6tKqOQ+TxTTJYSbpPnWvGTl7uMJte6HWnjUbANCy5S6PN6T6RxZa3kcM/mUsbGZ/UFIMvYknKOT48vMbBszu49ww3pbwnZOPf5TBgwj/Nb1INzMPSm2XoJwc3N9wvXLGsC6LKjhP5Vwru1M+E07i5BAEMu/JC7vBzO7L8ZRl1xhAqGFXztCknu1ma2VGL8UIdnuQfge3GYLHjXKdR1WGycQWh5uRvjt/h24MW2ajQnn462Af5nZKnH4uSxoEbYNofIBAHc/mJC87hyv/S6vrrx4DEzJFKS730ZozZNqbbRzHvscspyf4vY8DlgnXj9uR0j4IfexAmH/LEH4Hh5JOC9/5+7zM8Uel1dO+I50NrPRFh4JuMHMWmabJ095/b6UcmLbk3DBviKwDKHJ8Hmx+jsv7n4MoYp8E8KF7xyA2FTrEkJzluoMINw5ztdXhAOoG7AlIXG5Kn0iM2tFWKeFynb3voSTxAHU8ISfbZ3z0Ab4I/H3H0Abs/yes01IJevTE+WmykuW3TbLctPHZzON8OWusbhOfwNOdvfJ7j6NcDzsB+DhuYKjCXfvrgUGxGkycvf74j7Ltrx9zOwrwr4eA/R1923c/R5f0AQVwh3B1c2spbv/6u6pH+sDgavc/bu4Xc8E9ovNRuYREtrl3b3C3T9w96kxrkp3fzmelHsSmoCdBPxsZhfGspeM/1Zpjl9T7v5vwj5bi3DXL32fTrLw3N6UeLI/IFM5ZtaT8EOUfA4707FJXF4nYFKWk/CvcTzA8YQfkuOAL+LJeIfEtDsCz8cLz50IifWV7j7b3ae5e6Zmkfl4DjjRQic+SxF+eCHU2kM4hjMeWxaeJfwXCzdDTT/2nyacS2YRzj+D3P39Wsab1/mrJvI4NpJ6Eh452ZPw+EJLIONzidF1cbouwDnAEKtBvwRpqjsXdSDDvsrjnJvtXFXT35asYqJ3N3C+u6fWIWO81anm92ca4Xe5EDqwcHzXAeckfj/SpabvUF3h8eLrJuB4d6/MMtkOVL35+5a7P+uhOfvdVL3IOp1w0duD8LjAMAuPM1UXR2/ChXauJv3VnSeKwsLjPhuR+zv4RNq5/aZqir2fcF6bQ6hNPNvdf0qM3ydZXrbkIMZ3KOEC+4ps09REnsdMtfG5+1semiL3JPSLMCaxjOPi35cRbrgu5+67u/sT7j4vTrYO0NndL3D3ue7+HaGV2n5x/IHABe4+wd0nEh7NOTiOm0c4fy/t7vPc/c3UDZX49xPuvjuwXFz+ZcCYGFeNufsz7v6tB68DLxLOhUnnuPucOP6ZuA1zXofV0lGE42msu88h1HLuZVUf5zvf3We5+yeEJDL1Hd+H0DLsd3cfSzgX5SNjefEY6FCD2Kvb55D9/FRBqJld1cyauvsYd089apXrWIFw3Xlu3D+zyO93oyvQlHDdsQnhmmFNcj8+kY+8rutLObFNXfBfEA+aTwl3KnasSSHxYv8twgnm/+Lg84G7q7tTbmYbE+5m5F2b5e7j3P2LmFR8T2iysFeGSfcgNBPJ+GxPvKC+HzjDavb8SbZ1rs50wsVMSjtgeo47zAuJd2v2puoPeOoCJb3saYnx6Xffk+OzaUtoalMbnQkXDB8kfpiej8NTngbKgVFxW9ZFz/hJnfgWSiI91NrvS0iofzWzZ8xs5Ti6O+GubsoPhKafXQkntxeAByx0PHK5Zeh0JP5ofEqoBW7KghqkVK1o9c81VCP+sH1E+O6enza6k7t3SH3IUGtnoSOlF4Gb4rGfkunYhHCMTAI6Webn0LvF8cRzyCXuvjYhmX8IeDhRG5h8vrYXCz9/Wy0zO9AWdBTzXBx8MfARYbu/Q3g+cx7hLjeEO8oL3cSx0BHJc4SWAm+mjf7z2I/xP0+o4WoRY9/OzI6J45Od1aVfbCwk1/nLzDZJlFWjGpJMx4aZ3ZIo76w46SxCM+uvY3JzCfGcn2l6d//Q3X9z9/keWt/cSzi3Zis/l+rORRn3VYwj1zl3oXNVpt8Wq9oJX961RfG8O4zw6MiliVFZ461Ojt+ftuS+MVETVeKz0MlWW3d/MMc8qemn5FH+MYQa+HczjTSzvwBT05KqZK3kTKCFLXjG+H/xJtccD8+dv82CYzPZKdiBaYsaQLggzXW9Ud15osHFGqSbCOegrLU3hEc8kuf2Y3KUuTLh0Z4BhNYFqxH63PhrYrKHkuVlSw7MbDfCs9U7+IL+PGrEqnbu1ZtqjpmaxAd/tth4nnDtmrIM4VG7jwm/yb8tPCdLA93TkuezCL/5kPmaoHv8/38IrTZetNA51xlZwvuNBdcEHWNcNWZmO5jZfy20mplC+E50Skzyu1dtlZiKNZ/rsJpaGng8Ud6XhKQv+Wxx+nc8VfnSHUieC5L/zyVbeTVV3T7PtKwWZtbE3UcTKi3OAyaY2QNmljoech0rABM9di4Y5fO7kcrPrvdQCTOJcAO8RvlZBnld15dyYptq2pl3YlWNJoQ7VBCq+E+w0MR5HOFi8CFL6yWVUPv4mGe/e5wPp2oTo2TZuZompTQl3CWujeQ6V+dzqt6dXoOaN+9JJevDUwPc/XdCIpet7M+BvvHuXUrfPJa9ClWbp+aSvo0nEb6YqyV+nNp71d6XLyacFLuZ2f45yqp+4e5XEU4kLxGahYy10MRzzbTpXnD3bQgJ2VeEu3UQnotYOjFpb0Iz/fEe7sCe7+6rEprl7kSicxcz62mhKegXhB/XSUA/d0/1NDuKcAKvSxPOdDU57lJxdiQktU+5e3qP15mOzfEemiq/S7jzX6VDIgvNZ3cgQxNiDzXalxCaxS4TbwRsRtg/ELZHjeKP5d7rCzqM2SEOm+Xux7l7D3dflnAx8YEv6ODoU0KrlGTsSxOaEl/o7pk6cEge+8sCFe5+V0zuxpK4AeiJzuoyJMh5rRbx/OXhzn+qrNo8pgCJY8Pdj06Ud0kc/ylZvmNZps8Vbz7TJ1V3LlpoX2VQ5diPFxfNWLhJ8EK/LV61E768XulkoYOoJwiPN6R39pdPvNVJ//2pyXm3OunxbQX0T/wu70toivdkYppVCM8aT82j/K2A3RPlbQhcaWap5sXpzZBrKnmsJTsFuzdtugHkrq3N5zxRDO0ItaEPxu2XagUyNp+bZFmsTrhZ/EK8eTaKsA92qGa+Kix0Pnk7oWloXm+syMSrdjr3I9UfM7VR5Zzg7qcSvlMjCbWC31voqT75iMxPhGfJkwl0W3dPJQ6Zrgl+ieVPc/dT43G0M3CKmW2VmtDMVrDQYut7Qou0kcCyMa4aieefRwk15l1jkv8sVa95O1rVx1lSseZzHVZTPxFudCS3W4t4g6E6vxJuTKb0ShtfqFwkW3nV7fPchYWWgxsTjgsn1MRDjmMlSxyfAstmqSxILet3QnP3Qm+TvH5fSjax9VCN/ibh1RbNLbRb35dQk4aF11Jk3KgWXoOwn5m1sfAcx3bA/oSOWiCcvFYnVJ/3I+zko0i0xbcFtY9DMpQ/3NJek5EYt7mZ9bagF+GO4pNp0/QkPC85NG34+hba5Tczs5Yx0e5K7B2yjutM3I6p9xk2M7MWiYu4uwgnwB7xYuzU5LrnWueEbMn6XcA/zaxjvGP7t0TZwwl31E6I8aWaw7xKbpsRarTyMZ7wvFIzCE10CT+KV1t8dUVc7+3i/zclPCsyIH6uN7MemcrKl7tPdffb3X3DGPtsQlO2V+Iyu1p4T2NrQqI2nbBdIDTdOtnMlrEFzegfdPf5Fl4H8hcLTaimEu7yV8QyzyNclK9EqEVawUMzlx8ScTmh2e85Fp4/bWfh+Z+NLTwPTCyrBaGpC8Cfx1Gc9qi4b83C80nHUoNnUi00o3wBeNvdM91dvgs43MI7RDsSmrsMifH/QagBvN7MtrfwnGkfQgdKY4k9+5nZOWa2TvxutQBOJNwZHEVoSvNp4mL5aWApMzspHpNtLb5GJa5jC0KyQvwOpbZLpnXrYWbd43zrE5rLnpuY5FnC8fDn9IRj/0Z3z1Zrlzz2v45hHRD3xVKE82TWH4e4jVoQfh+axHUoj+OqPX9lKK+Qx8ZgwvN3y1p4XON04jk/y7L3iue8MguvbDmI8OxRtunLY3xNgLK47qkWDsPJfS56CVgrsX7VnnMJnXO86qFZXCqGrL8tGeIti8trGv60Fragl+amhBrfWYTHJdKbTr4HdEicu3Kuv1Xz+xNVOe+aWZNYXjlQHstrkhif6zenyrFP+G6knrfrR9iPtxPOxdmWn2t/HkK4UEqVN4Jwrki9cuqv5NkHhYXXhW2XWj8LtbKbEs5buebbkNB0eaHekC3xGozqzhMWXg0yJPF36jxmQNMYV1kcl/McVYOy/iDckO0XP6kL7LXJ3GN1tm2QXN5HwAoW+q8wC025d6IGN0vMbEtCy4w9PbwhIdfycm6rDA4h9zGTT3wHJs6hSxNuklc557n7RHe/2kOz/z0JzS/fNbNU7+LvAVPN7PT4XSy38BqndeL4+wnXVJ0tvFbxX8Tez81sJzNbPn7PphLOaalrgjsJN4M7ELbfGjGOifmuX5pmhHP/RGC+hcd7Mr066/y4HzYh7O+Hq7sOq6VbCH1pLB3L62xmu+Y570PAmRZ+r3oQHltKGk/tK5kySS+vun2elZmtFL9TzQnXlrOoev2Y8VjJJN4c/4bwLG4ug4Hj4+9gR0KN8Z+/1dWc+zOtQ3PCueWlbNMkgyzZD+EH4XnCRX56b2sHA+9kma8zoYnvFMIXeyTwtxzLGcPCPfvtT6iyX6gXQ0IzxW2ylHUK4e75TMIdmOsJzauS05xJ6DQkfd7NCCf4aSxoprxpodY5rqenffrEcUboiXJy/FyeXPdc65zYV/PJ3DNgc0JHSVMJX+ZT0savSXilxyxCz7RrZijDU2UTnkX4qAbHUTPCXeHJhOcxITTbvCQeV1MJtbMnEO5SjwH2S8x/GaE20bKUdSDweS2O7zJgg/j/bnH//RH34XBiT7dxun/F42ki8XUkieN0FOG1IOMJd4BTvRX2I0OP21li2Z5wI2l6XMZw4K9p27/KJxHb83F7TCckWmeljh3y6BWZcEPE4zpMT3x6p32vxsd9NZi0XmYJvXh/Fo+h8YTXSXRMjP9nHD+VBa0KNozjrgD+nlbe6oSLkd8JzX/OSFuf5GdMju26aTyeZsb9dGDa+E6EBDzVE+S5sczkdpiemL5bnL5ZYtiWhNqUP2Kst5PodTRDTEMyrMMh+Z6/snw3a3xs5CjvfMIxOJFwY6JjjmnfjOs9lXDu3K+asg/JEO+QfM9FhARl3/j/fM65zwC7pA3L+tuSId7NM8Q7PI7bLP49M+142SQx/3+A0/NZf6r//WkRj72uiWHnZSjvvMT4MRnG90mMfx9YL8dxmt4r8khgjXz3Z9q8w4k9exKeE55I1R45zyPR4y2Jc1fc1+/HbTOF8Gxi1t/DRBm3Eh57Sh/eM5aV6vm9uvPEK8ljK65L+npvns85qiZlpcXw5/ZI2785e0XOsLx9COfiafF4uowFvfZW2Qdp55jU7/9rhGuN5DH/XF3Xr7pjpgbxXRzXa0b897bUfq5mWc2AdRN/dyckJeMIv0P/ZUHvvy0Iv/W/xs91QIs47uS4X1LLPydR5rokfjtq80k/Dgg3K8cTvhd3E1oMpX7bN48xnE2oof0RODjtnLLQdVhy3jzi+fMYJPzmnEL4Dk0jXLdekuP4/XP/Elpw3R3X40vCNcO3iWl3jfFPIbxeqrryNiHx250h7hUIzcCnAE/ksc/PI/v5qS8hMU6du58GuudxrGTcxnGf3pztexCHNSU8qjAlxvtnuYn9kuvcX2X7EW72PpbPMZi6uFzkmNkdhLs+Oe+Y1sNye8blbtCQy43LXhzX+VDCO0hbEBK978zsUUIHOfn2+CySlYVm2nu5+xdFWv4lwAR3vyaPaa8k/NhW10GL1AML79kdSrgAzfnjauEZztuKcd5MxNCZkPyv6VU7qqtNWccDvdz9tIIEF8rcFjjG3XfLY9qdCRfF+1Q3bR5l7UP4zte5rFou/yBCE8wz85i2GeGGQ19f0LlQbZdbsLK0PFmUmdn/EW6UblbsWBparD39iPDKoF/N7EXC2xZGuPsWBSj/XMINiOaEypcKM/sf4fVBn1U7/6Ka2IqI1FW8EDrFQ8+9IrIYiAn1NM/dSZCILCYsvPJvWUJT7RUIrW1uyOeGszQsJbYiIiIiIlJSLPRWna011aoeOv0qxHKWJiSzyxCa1z4AnOnucwtRvhSOElsRkUbAQk+e1xI62rlDtcQiIiIi+VNiKyJSZBZ6Hf4a2IbQmcb7wP7Feq5XREREpNRkfQ+RiIg0mHWB0e7+HYCZPUDoZTFjYtupUyfv06dPw0Unshj64IMPJrl752LHISIi+VFiKyJSfD0Ir89JGQusl5zAzI4EjgTo3bs3I0aMaLjoRBZDZvZD9VOJiEhjke0l1CIi0nAyvZi8ynMi7n6bu/d39/6dO6sSSURERCRJia2ISPGNBXol/u4J/FKkWERERERKjhJbEZHiex9YwcyWie/O3Q94qsgxiYiIiJQMPWMrIlJk7j7fzI4DXiC87udOd/+8yGGJiIiIlAwltiIijYC7Pws8W+w4REREREqRmiKLiIiIiIhISVNiKyIiIiIiIiVNia2IiIiIiIiUNCW2IiIiIiIiUtKU2IqIiIiIiEhJU2IrIiIiIiIiJU2JrYiIiIiIiJQ0JbYiIiIiIiJS0pTYioiIiIiISElTYisiIiIiIiIlTYmtiIiIiIiIlDQltiIiIiIiIlLSlNiKiIiIiIhISVNiKyIiIiIiIiVNia2IiIiIiIiUNCW2IiIiIiIiUtKU2IqIiIiIiEhJU2IrIiK1Mmt+JT9Nm1vsMERERESU2IqISO2M//knnhhyW7HDEBEREVFiKyIitdNn6aU5/vjjih2GiIiIiBJbERERERERKW1KbEVERERERKSkKbEVERERERGRkqbEVkREREREREqaElsREREREREpaUpsRUREREREpKQpsRUREREREZGSpsRWREREiqYC8GIHISIiJU+JrYhIAzGzMWY20sw+NrMRcdgSZvaSmX0T/+1Y7DhFGtJz//0aXKmtiIjUjRJbEZGGtYW793P3/vHvM4BX3H0F4JX4t8hio1u7VsUOQUREFgFKbEVEimtXYGj8/1Bgt+KFItLw1l61J2ZW7DBERKTEKbEVEWk4DrxoZh+Y2ZFxWFd3/xUg/tsl04xmdqSZjTCzERMnTmygcEUaBwdmFzsIERFp1JTYiog0nI3cfS1gB+BYM9s03xnd/TZ37+/u/Tt37lx/Ecoiq9Kdo8+8icGDB+Ml9kzrO19O5aILLyp2GCIi0og1KXYAIiKLC3f/Jf47wcweB9YFxptZN3f/1cy6AROKGqQscubOncu4ceM49dRT+d+Ij3l63izmN2nCjlttRY/u3YsdXlaVlZX8/PPPuDtXnXsGVjm32CGJiEgjphpbEZEGYGatzaxt6v/AtsBnwFPAwDjZQODJ4kQoi6JPvhnPJ5+OZIPNtqeyvCVfff4JgwcP5uFHXmS99Tbg7rsf5Pvvfy52mBmN+OJnVuvbn70OO4WLLrqQRx55pNghiYhII6bEVkSkYXQF3jKzT4D3gGfc/Xng38A2ZvYNsE38W6Qg/vOfK5gzx9lhhwMYOnQoLVu1YptttmHoXXdRtsQaDBhwJP/977vFDnMh730xnlNOP5dVVlmFoUPvYrnllit2SCIi0sipKbKISANw9++ANTIM/w3YquEjkkWVO8yeN5c/Jk9mxsTRrLbq8lx+0fG0ab6g5+Gl2sE7Lwzh0QfvpUWLciZOnEizFq1p37a4r96prKzk8Sde4biT/kXzJhN556036N5drwMSEZHqKbEVERFZhLz62qs88ca7vPLQvdz34IN06NB+odfpmBk9l1qCE044DoDl+m5Jn+VXYtBVp7PMMssUI2w+/PBDPvnkE/75z3+yz6GnceZJh7FUp7ZFiUVEREqPmiKLiIgsAr7++nv+7/9OYcDBA/jjN2PIkCH0+8tfcr4jNjXuvAsu4o8pkznssMM47bTTGrzX5A8/HMWAAcfx4Isjuf3227n2ohOV1IqISI0osRURESlxle688eXnDBlyGx2W24orLzyFddddt8o07s7dL3zDnHkVVYabGQfuuiE33XgTlS27cesdQ3j2f780WOzjJkzmmrue4/vvv+ai049khx12aLBli4jIokOJrYiISIl7+aWX+OdRRzBkyCA+e30Indo3rzJ+9OjRjBs3jkv+vj/vfbHwG6XKy4x1V1mS4c/cyz577spLD/yHp556imnTptVbzNNnV/Lmux+y3jpr8cf3r/HQQ0NZe42VctYwi4iIZGOl9pJ2EZHFXf/+/X3EiBHFDkMagS+//JIPR/3CnKkTaN+6GXvuuedC04wdO5b999+f008/nZkzZ7LPPvtUW+6no75m4KGHsfbqq3PahTexYtfC3wd/+Y33OHjAQE44agBnnHFGo0tozewDd+9f7DhERCQ/qrEVEREpMfMrnN13P4Cdd96FH74ZycCD9l8oqa2odO59YRT7HHwia/z1NFbsu1FeSS3AaiuuyPGnX83zLw5n+03X5p57HihI3O4wr8L56effuOTKp7jq2ls59dRTG11SKyIipUe9IouIiJSYB597n7f+9y577rMfBx1+AuVpt6mnzZjDwy99ygWnH8l2m6/HdaftRE1yx3KDQ3fpz56b/499992X1q2bVz9THkb9NJb7n/uE776bwCGH78Z+O6+tpFZERApCTZFFREqMmiIvvmbMmMGFF17Iyy+/zFZbbcWll15KWVnVrHb+/Pkce8JZjJ9cwYZrdeWkk06iWbNmdVrusGHDePvtt1lhhRU4/PDDa1XG5MmTOeigg2jXrh2bbLIJxxxzTKNOatUUWUSktKjGVkREpAS8MXIS/zp5APN9HlfdfDP9V1utSlJbUVHJnDlzOfHE4znssCPo1WsZevbsUpBlr7HGGrRr14499tybWwY9w5BBV7HaKn3ymnf+/Pm8/+1cLjz9WPb627nsuunyLLnkkgWJS0REJEXP2IqIiDRilQ4/TpzJdRefwrw5Mzn61CvZZJ11aNWq1Z/TuMOzb3xK+279uPv+Yay5Zr+CJbUAvXv3Zr0NNmL/Y69j6vRZzJldfW/JDswB7rjjQTZZvTstm8zjkN3WVVIrIiL1QjW2IiIijdgfU6dx2En/plObXjz1xNUZE8Nbbr2VR198h03W7s6WO55JkyaF/3lv0awJN5y/Hx/utyndO7Xh6hseYqfdtmeFnu0yz+DOjYMG0aKyKXvusRt33nkjZY246bGIiJQ2PWMrIlJi9Izt4qGiooJLLrmEF154gdZtl2DI0KF069KxyjQ/T5rNZVffRJfePdh0le706bM0vXv3rvfYZs2aTY9em9Br6abcedv19O3bl6ZNmwJQWek88MAD9O7di7POOosHHniUZs2a0qlTh3qPq5D0jK2ISGlRja2IiEgjM7/CuX3oo1xx/WBGvPMyS/fuuVAHUJ9+/h3DX3uTbu2X4B9H7E15WVmNej6uixYtmvPzT29ywy2D2HGPAay80ko8/sh9dGzXgg+/+JaBR1/I4/ddyUsvvUTz5oXpUVlERCQXJbYiIiKNyB8V8PPEP3jv8wlccu1dLNWtx0JJ7aSZsPcBxzJp/ChuvOVOmqS/76eemRktW7Zg/wFH0XWFjfn222+546FnGTBgN26750nWWmUpll9+ZSW1IiLSYJTYioiINBK//AHnX3IxP37zMVdceD6rrbZqlfEVFRW4O3fediu/j/+EJx9/kr+ssWaRooWeSzZhwE5r8N57c9hz3/15/P5b2fnAf/H3w3ZmxRWXKVpcIiKy+FGvyCIiIo3ErHnw2ccj6b/5gIWSWoD+/ddhlb7r0KNzB74b/TUbrd+f9q2Kf4967bXX5vDD/sb7b3zCsXv1Y8UVVyx2SCIispgp/q+hiIiI/KmsTU+O2Wf9KsO+/v5Xnnv9U2Y1W5qbbr6SrddflsbUv3B5eTlrbboj3Zb5mPKyxhSZiIgsLpTYioiINCJl7ZeHsqZ//j1l6kyO/seVvP7CQwwdMpit11umUSW1Kett2JfefboVOwwREVlMqSmyiIhII7FEB1iyQxlzKhcMmzdnBuNH/ZdB11/H/rttjjWCd8FWVjo//Tq52GGIiIj8SYmtiIhII9GxCbSfP4H3fpjz57DOnTvz+ci3OOSQ3SgvLy9idAtUVFTw3Osjix2GiIjIn5TYioiINCKzJnzGhHHTih1GTk2alPO3fTfFix2IiIhIpMRWRESkEWnXZ0vKmrYqdhg5zZ49l133+wfTix2IiIhIpMRWRESkkZgLTP51NJXz5xU7lJzKm5SzyVab07rYgYiIiERKbEVERBqJidPgt8k/gjfyxLa8nO13/KsuIkREpNHQb5KIiEgjMXsOzJ1b7CiqN3fOXE4/8e9MLXYgIiIikRJbERGRRqK8HMoaR8fH1XCm/vE7ldVPKCIi0iCU2IqIiDQSndvAEq1ao59nERGRmtEvp4iISCPRuim0bDILGvmLdLxxhyciIoshJbYiIiKNSiWNPbE1W3hYizLovdyyWGm0pRYRkUWMElsRkQIyszvNbIKZfZYYtoSZvWRm38R/OybGnWlmo81slJltV5yopbGYOB1+nwlNmzYrdig11r4czv7HQbRo3rTYoYiIyGJIia2ISGENAbZPG3YG8Iq7rwC8Ev/GzFYF9gNWi/PcZGaq7lqMTZ0N0+fAlqs0KXYo1WrbpjXJittKh5fe/oJ5FepSSkREGp4SWxGRAnL3N4DJaYN3BYbG/w8FdksMf8Dd57j798BoYN2GiFMap1bNoEVTmDarotih5NSiRXOeeew62iWGTZwPj979KPNL4X1FIiKyyFFiKyJS/7q6+68A8d8ucXgP4KfEdGPjsIWY2ZFmNsLMRkycOLFeg5Xi6dYu9Iz8zjdzih1KTvPnz+fGWx9kdtpwb+TPBouIyKJLia2ISPFk6IInc2bg7re5e39379+5c+d6DkuKZewUGDe12FFUb/78Ch589EUad/otIiKLEyW2IiL1b7yZdQOI/06Iw8cCvRLT9QR+aeDYpBEpMyjXL7OIiEiN6edTRKT+PQUMjP8fCDyZGL6fmTU3s2WAFYD3ihCfNBLd24emyCIiIlIzjb/bRRGREmJm9wObA53MbCxwLvBv4CEzOxz4EdgbwN0/N7OHgC+A+cCx7t64ew2SevXzFBg/rdhR1M4STWCjbbakvIle9yMiIg1Pia2ISAG5+/5ZRm2VZfqLgYvrLyIpJbPnw9z5xY6idpoaXHrKXykry/TouIiISP1SU2QRERGpkSZNmnDYgF1pkTZ8TnkZmBJbERFpeEpsRUREGhlr5MlhkyblHHzAX2meGPb7fDj51BuYNUt9JYuISMNTYisiItKYlLVi/bVbFzuKnGbPnsP2uxzHH4lhcx0+G/ktlRV6TFxERBqeElsREZHGpLw93coa/8/znLlzix2CiIjInxr/L6eIiMjiZN6vvDNqRrGjEBERKSlKbEVERBqVctZdvnn1kxWV0axlG8qLHYaIiEikxFZERKRRacrEGY3757lJ0yYcfuRBtC12ICIiIlHj/uUUERFZ7Mzmo+9nFzuInMzK6NpjGbzYgYiIiERKbEVERBqZbVZrVuwQcpo3dw6X/ut8phY7EBERkUiJrYiISCMz9rf5xQ6hWnNmz1SNrYiINBpKbEVERBqZj36o+iodd4+fIgWUkeUxREREpGEosRUREWkkmpZBeYZf5ieffJIzrryNmfMqGj6oDFq0aM5TD19Nu8Swzk3gqQcvoFWrlkWLS0REFl9KbEVERBqJ3ktA9/YLD+/WrRsTJs5m2rRZVDZ8WAsxM5bo2K7KRcTIL8fw1LC3qahoHMm3iIgsXpTYioiINBITpsFvMxYevt5663HthSdy+aUXcO011zR4XPl45pmnOeJv5zBnztzqJxYRESkwJbYiIpLVvvvuy5gxY5g6tbT6v73loXf5/Nff+e33acUOJW/z58/n2x/GMWXaHKb/8dtC49s1gyOPOIwbbriBlVZZhTfffIspU2cWIdKFzZ07l2mTf2aJDs0w05O2IiLS8JTYiohIVh26r8SyK63LUcefxmdjplHZuHovWsjr74/m6eGf8fvvUyibMYNDj/ono3/8jWkz5xQ7tJw+GfUr19/2MHvvsiO9l+rMTRccz9PDR/Lz+ClVplt55ZX57Otv2Gi7vdhs2wPZ96Tb+G7swklwQ/r0mwl88NFn3PvYcJ59/hZat9YztiIi0vCU2IqISFb/POc8zjzznzz55DAOO+LIRt/M9JS/n8bx/7iAFZfryVJLtoHZ47jv/gf44Ycfix1aTtdcex2nnnoGW265Jffeeyunn34OBx38d9586+2Fpm1ZZhxxwAHcduttrLFMSw499HDGjBnT8EFH/77scnr27MngIUNZbfW/FC0OERFZvJk38rvvIiJSVf/+/X3EiBENtrzZs2czduxYjj3+eMrNeODBh2jTpg1ljaTFaUVFBffffz9XXnklc+fO5elnn6dLl6Vo0ayMCRMmcfPNNzJs2DD69u3L0KFDix3un9ydyVOm8eD993DRRRcxbNjT9Oq1NF26LMm8efO5+ebbuPXWG2nfvj3PP/887dq1W6iMb36awiF/O46d9zmU0w7ZkrIG2ilz5jtvvPYyX331FXvssQfdunWjrGzRulduZh+4e/9ixyEiIvlZtH6FRESk4Fq0aMHyyy/PPcOGMXk2bLf7gdz14OPMmzev2KExqxLuu/9+jj7uVM445yI+++wzllm6F61bNqW8vJxu3bpy/vnn88Zbb/Pr7/P5atQoGsvt3Lfffof19/gn9z31Mvc//DhrrbUmXbosCUDTpk04/vj/47PPPqNLn1U5/ozLmTJ94e29fM/2HHXAtgwfdgcTJoznscce47ff6r9p8oOv/8q+Bw6kdccu9OjRY5FLakVEpPTol0hERPLSqbwJd9w5lG7t2nPo/gdw4WV3FTWer8ZM4syLruaoo49l/Q12YtNNN8/YcZGZ0bJFC7bceleOOvlqbnrgv1RUFvelOS+99BIHHXQQF512MPc99BjrrLveQrGbGWbGdTfdypob7cSFt7zEkGGfkGxpZWYMGDCAoffcz5ejx7Lngcfy9JtfUVlP2ftP46dyyyMf8OgTz3P9DTew59771s+CREREakiJrYiI5MUMVu/Tmdtuu44ddjiM54bdw5QpUxq85tbd+fHniZx+wY0Mvvpinn36KYbcfgndOrXOOk+T8jKOO2wnDjrscAbddBkjfpjMlClTmD9/fgNGHmL/ZdIfPDn8A/pvfyS7bNmP3u2gVdPs8/TuUM6AXfoyZcxwzjj+AO5/8UvmzKnaGVbX1rDuWn/hxGMGcPm5JzFp4kRmzy5sh1nTpk3jw/fe4pwT96UJc9h3z91o37ygixAREak1PWMrIlJiGvoZ20wqK52ffvqRnXbaiV133ZWttt2TLTZds0GW/cEHH7DLLruw5pprcsopp7DFFlvk/YoZd2fOnDnsv//+fPnllxx22GGceuqplJeX13PUwbx58+jTpw8XXXQRAw85BIO8YndC7EcddRQff/QRa6+9Nrvvvjvbbrttlfndnblz57LTLgfQc+m+/OeSY+nUqVOdYh4//jdGjPiIk08+hhVXXJEBAwaw19575x17qdIztiIipUWJrYhIiWkMiW3KC69/yOHHn0uz+dP44ovhtKjHZf0+dRa33fU4X3z1Dcuu1J1zj/9bncob/ODznHrCkZx66okcfcKpLFlPwVc6vPHJ9wy7+waOPOoonn7zQ049fL9al/fpV99w6U0P8sqjd3LXwy+w/YYrLDTNpN9ncMyJp8Hsiay//vqccsoptY59yKMv8LdDT2LXfffjkdvOWWyep1ViKyJSWpTYioiUmMaU2M6e54z5aQKPvP4drzzzIKceuh1/3XH7gtfkzZo1m3NvfI6bLzqam26+hT332Y1W5XVbxtQZc9l1l7355JOPOO3Myzjx2D1p0bxpwWP/449prLX+Roz/aSzPPDOMdTbcKGfT4+rMr4Q/Zs1nm802pKJFN665+lo2XavXQrXOn/80joH7HULlrIl8+OEHNV7OvPmVXP/QBwy6YxC7brwsJ558Il06NFuka2mTlNiKiJQWJbYiIiWmMSW2EJq/Tp/tnH7RTXzwwYc89+D1LNE++/OuNTV7Puyx+158++OvHH3IXpx44okFqzWsqKjg10kzOOqki/h5/G+8/cxNtG5ZuAdHv/32W/bY42h6L9+dxx8cRHl5ecESw6lTp7L9X3fjy6/GcvklZ3D44YdU2S7uMG/eXI4++mgOPPBAzIxNNtmEpk3zy6qvv+slLv3XiQx77VPWXLpssampTVFiKyJSWpTYioiUmMaW2KZ8/PHHPPPMM8yaNYs11liDvffeu85l/vLLL1xy1Y20bdWC3ff/P9ZdpW7Pi2bzzjvv89prrzBz5jQ22GADdtpppzqVN3fuXC688EJee+01/vKXvhxw5JlssmavAkW7wKQ/5vDUMy9ywVnHs//++7PtttuyxRZbVJlm3LhxDBo0iLvvvpu99j2IvQ8+mjWWz74dr7jiCn7//XeaNWtG27btOPnkkxabWtokJbYiIqVFia2ISIlprIkthNrb259+n+ZexsBd+vPmqDlsvGLtmq/Om1/BJhtvxLLLLseNN95Ax44d6yHiBSrduXzwA1x79ilsvMuxDL76H7RpVfPa27uf/B+3XXM+Y376mXMuvIL9d1qftm3b1kPEC3z08SdccOMwRjx/H08/8yh9/7IK6Zv8pgff4ddJ0znxwE3o1KHlQmVUunP3Ux/w4lsjWbrPUhy005qsuvRS9Rp3Y6bEVkSktDQpdgAiIrLoMDOO2GkdUvdMTx2wGXcNvYuVV14x7zKmTZvG5MmTefGDibRZoic7HXBSvSe1AIax16brMWzZlXntsesYcfCObL7xWjUu55M3H2Ha77+y2w47ccS+W1NWVv+1nf3W6MvZR5ez+/P389Q7b7D66itRblWbDh+19wYAlGeIZ87c+Tz64sf8+8IzGPbAbSyz7DKULYa1tCIiUrpUYysiUmIac41tur0OO4Ov3nueoUMHsfbaa1c7fUVFBSeccDbt25ex0korsd9++9G8ecO/LPXee+9l4ow2nHTkrlWGP/HEE4wcOfLPv1u1asUpp5xSpUb6+eefp2/fvnTv3r3B4k155ZVXGD58OO2X7MYKa23Hxmv0YMn2ubt7dncu+vdVPPvuz2y9RmtOOeWUBrmR0NipxlZEpLQosRURKSAzuxPYCZjg7qvHYecBfwMmxsnOcvdn47gzgcOBCuAEd3+humWUUmL74/jpDL7lSh548EFWWH55Hnn0UZqUly/UEVFlZSUVFRUMGfYpZx53HBdefj7/d9C2RYo6s+eee47DjziCa66+mi5dugDQtGlTNtxww0b1DGplZSUPD3uNqwc9w2Wn7ctG669NkyYLN9Byd+bPn88ll1zCkKF388Irb7HiMotv0+N0SmxFREqLElsRkQIys02B6cBdaYntdHe/Im3aVYH7gXWB7sDLwIruXpFrGaWU2ALMnz+fZ9/+nsP3+ysV1porr7mCQ/fZ6s/x0+c6r732NvvtsTM9lt2Q/715P23btKFJk8bVC+/gwYP5raKCEw87jKaNvIfgykrn9Y/Gcvo/b4Xf3+fZl5+hQ6smpDapO3z13Rj6910Pb+J8/vH7LLPM0sUNupFRYisiUloa9y+ziEiJcfc3gMl5Tr4r8IC7z3H374HRhCR3kdKkSRN22WwFTj/1VI44aDt+/PIdJk6c+Of4a2+7m3sefZ5jj/0bg+69gfbt2zW6pDZlxMsvM2v69GKHUa2yMmOLtXtxwTmH8P2PX3PMaRfx5TffJqZwbr1rCMsvvxTnXHQNnbuqplZEREqbamxFRArMzPoAT6fV2B4CTAVGAKe6++9mdgPwX3e/J043CHjO3R/JUOaRwJEAvXv3XvuHH35ogDWpHyeffDIffvQpfzvtGuaMe5+zzzqLxx57jA033LDYoeU0duxYDjnkENq1a88jjzyCeyVlZWWNqhlyusrKSl555RUefvhhPv74E15++SVee+0tbr31Fv72t0NZYYUVWH311YsdZqOkGlsRkdLSOG+Ji4gsWm4GlgP6Ab8CV8bhmTKijHcb3f02d+/v7v07d+5cL0E2lEsvvZT27ZbniL024OPvJvDR51+zwQYbFDusavXs2ZPD/341U2ZWctbVj9K1Wy9efvllGvMN4rKyMrbZZhuuv/56rr33BVZaZVUuvOoOzr7oKnbddVcltSIissjQ635EROqZu49P/d/Mbgeejn+OBXolJu0J/NKAoRVFixYtuOeeK+jY8TF6tIFuS7Yrdkh523/7v7D/9o8z+qfJvPP8+hxwwAFMmDCh2GFVq3nz5qy/fDMOOPAgVlmjPxuttXyxQxIRESkoJbYiIvXMzLq5+6/xz92Bz+L/nwLuM7OrCJ1HrQC8V4QQi6CMldfYnq1327PYgdTK8r2WYOVlOvHlx8WOpCaMy/59KbNzdk0mIiJSmtQUWUSkgMzsfuBdYCUzG2tmhwOXm9lIM/sU2AI4GcDdPwceAr4AngeOra5H5EXJEp0703u5FYodRq2dfvrZ9OzZs9hh1Miroydw5c1PFjsMERGRglONrYhIAbn7/hkGD8ox/cXAxfUXkRTKqG/GMvztkey0x+Ys2bol5118HWPH/lr9jI3IuHFzmPjLuGKHISIiUnCqsRUREcnDO++8xdFHHs7xxx7LO++8zauvPQEsNhXsIiIijZoSWxERkTzsu/cuHHXYLnz50UcMefRTzjn9fD777LPqZxQREZF6p6bIIiLS4Jo2bcL226xDixK6vdqqVStuueWWYochIiIiGSixFRGRBteyZXPO/numx5FFREREaq6E7pWLiMiiYvr0mex18IVMml/sSERERGRRoMRWREQaXGWlM37C71R6sSMRERGRRYESWxERERERESlpSmxFRERERESkpCmxFRERERERkZKmxFZERERERERKmhJbERERERERKWlKbEVERERERKSkKbEVERFpAC+//DKjR48udhgiIiKLpCbFDkBERGRxsOqqq9KmTZtihyEiIrJIUmIrIiLSALp3717sEERERBZZaoosIiIiIiIiJU2JrYiIiIiIiJQ0JbYiIiKLic7tmrNM76WKHYaIiEjB6RlbERGRxYAZ7NCvKzv0263YoYiIiBScamxFREQWA+7w4qcTuO72YcUORUREpOCU2IqIiCwm5s6vZOasOcUOQ0REpODUFFlERGQxYAY7rrUU26y1V7FDERERKTjV2IqIiCwG3OHVzyZy6+Bnix2KiIhIwSmxFRERWUz8MnkWX4/6sdhhiIiIFJwSWxERERERESlpSmxFRERERESkpCmxFRGRhmdGi1atKLdiByIiIiKLAiW2IiLS4Jo3b8ZRx+zLkuqbX0RERApAia2IiDS4srIyuizVvdhhiIiIyCJCia2ISAGZWS8ze83MvjSzz83sxDh8CTN7ycy+if92TMxzppmNNrNRZrZd8aJvOE3Kjf4rdih2GCIiIrKIUGIrIlJY84FT3X0VYH3gWDNbFTgDeMXdVwBeiX8Tx+0HrAZsD9xkZuVFibwBza+o5LNRY4sdhoiIiCwilNiKiBSQu//q7h/G/08DvgR6ALsCQ+NkQ4Hd4v93BR5w9znu/j0wGli3QYMukkr3YocgIiIiiwgltiIi9cTM+gBrAv8Durr7rxCSX6BLnKwH8FNitrFxWHpZR5rZCDMbMXHixHqNuyFUOoyd0oQK5bYiIiJSAEpsRUTqgZm1AR4FTnL3qbkmzTBsoXTP3W9z9/7u3r9z586FCrNo5s+dx4vPvMz0ymJHsviYg/PRO+8XOwwREZF6ocRWRKTAzKwpIam9190fi4PHm1m3OL4bMCEOHwv0SszeE/iloWItlhYtm3PO6QNov8g/Tdx43HDjjdz273P45IsvefrNj5mvmwoiIrIIUWIrIlJAZmbAIOBLd78qMeopYGD8/0DgycTw/cysuZktA6wAvNdQ8RZLeZnRa0n9BNW36TNnM3nyZO4YNIjr/vMf3nj1PnbadFlOPupgtt9uG2bMmFHsEEVERApCVxUiIoW1EXAwsKWZfRw/OwL/BrYxs2+AbeLfuPvnwEPAF8DzwLHuXlGc0GVRM+C4S+m8VG8+/fZXRn//PWutuQannXoCH3/2CT//Xsk+h5zCZ99PoaJSDzuLiEhpM1evlCIiJaV///4+YsSIYochJeCv+5/EFuuuyPqbbM3G/Vf8c7i788I733L/Aw8x8rPPePHRm+m0RPsiRtr4mNkH7t6/2HGIiEh+lNiKiJQYJbaSy4wZM/j2p9944p1xbLdeL9ZZpStlZZkbaE2ePJkjjjiCb779me13OJiLLziSZs2aNXDEjZMSWxGR0qKmyCIiIouIb775hg023JBjTziR3k1+Y91Vl8qa1AIsscQSPPLII+x55Dk8+cztnHXWWcycObMBIxYRESmMJsUOQEREROqmotJ5feTvXH7RLVS0WYVHnrybri2b5jVvWVkZ5xyzExtv0IfjDz+EWXYru+2xE9tssEI9Ry0iIlI4qrEVEREpYXPnzuOPKb9z+H7bsuqyHXjivhvo0qJm963LDTbrtzobrrMtg2+9kiG3XsHMmTOprNQ7gUREpDQosRURESlRcyvgtLP+zV/W3oKdt9mQ/1xyFiss3Ynw1qmaaVoGt950IWNGf8gvP3zNKquswgMPPMj4KXPqIXIREZHCUlNkERGREjR79mzOueR6JlR24PIbB7P/9mtSVlbzhDapSZNyunTpwmuvvcbgh57h+OOP4qgxU7nkrKMKFLWIiEj9UGIrIiJSYoa9Poprrx7MxHHvcMcDj7Fm707k6COqVvbZ7a/06nQ3B+y3Hz//OonLzj2RpTq1KexCRERECkRNkUVERErEvHnz+N///se9t5zPhO9fYvMNdqf/0p1oUg+/5q2bwcYbb8ph/7iWUSOe4b9vvcxXX31V+AWJiIgUgBJbERGREvDp6En8+/KrGDBgAMsu04cXX3iGa68+mVo8Tpu3Fs3K+fc/9uO/777DN998w0knnVTjMj74+Bu++vqnKsOGDh2KuxcoShERETVFFhERafQqKyu5+86bue3WG7l60NMctlv/Bo/hhBNPptvqWy80fN68+Zxxxnn0778ad955J8suuxw333zTn+/P7dK5A82aVr3cuPnmWxgwYECDxC0iIosH1diKiIg0YpUOdz/wGEOH3sk7bw5nwM5rFyWOZk2bsP92ay403L2SESPeYubMeUycOJP7H3mGM88+l9SLglo2N5o3q1qtvOqmAxsgYhERWZwosRUREWmknn/+ef5zxVW8NeIrrr7pLpZdfiWalNdj2+MczKA8w1VDWVkZ++yzN4cfPoAPP3yLi6+6g/JmZYz+7jsAHnroIV5++eUq82zdr11DhCwiIosR0zMuIiKlpX///j5ixIiiLT/1s1Gfz3Yu7iZMmMC9997LJ598wmabbcYaa6zBWmutVeywFnLvvffy8MMP89BDD9GsWbM/h3/33Xe0atWKrl278sMPP9C0aVO6dev25/gNNtiA//73v7V6325DMbMP3L3h23yLiEit6BlbERGpkR/+gNZNoXPrYkeyaHJ3Bj39OV99/DH7H3sJG67WmXatm1U/YxF8/fXXPPvss1RUVFQZ3nuZZTlw/0O59ZareeWVV/j73/9eZXzbtm0bMkwREVkMKLEVEZEaad0UmpcXO4pF2z23XMbpxx3A9uv2KHYotfLuhx/z4Wcf4O7MmTOHKVOmVBnfurXuioiISGEpsRURkRpRTW39u/mGa9l03ZWKHUatvf/6q3z7xWd//n3qqaey/vrr//n3hRdeWIywRERkEabEVkREpBExs5JOaudXVLLr7vuyxx570r59ewDWX3999tprrz+nuWPIfcUKT0REFlHqFVlERERqp/kSUN6SybMXDPpl0gwOPO4/fPbZl3++yzbdOTc90kABiojI4kKJrYiIiNTKnnvsznLLLcvFF1/057CObZtx9ol7s+aaf8k632N3nN8Q4YmIyGJEia2IiIjUSt+Ve/PGay+y6zabcvbZZ3PBjc/wl9VX59MP3qFHj9DxVZs2bWjZsmWV+b7+6MNihCsiIoswPWMrIiIitda5c2e6LNWTwY8MB4bTqXtf1tls1z/HH3zwwQu9r/app55q1O+wFRGR0qPEVkREROpk2WWXY/CQoRjQtnVzNujb689xmRJYJbUiIlJoSmxFRESkTtq3bcF2Gyxf7DBERGQxpmdsRUREREREpKQpsRUREREREZGSpsRWRERERERESpoSWxERERERESlpSmxFRERERESkpCmxFREpIDPrZWavmdmXZva5mZ0Yh59nZj+b2cfxs2NinjPNbLSZjTKz7YoXvYiIiEhp0ut+REQKaz5wqrt/aGZtgQ/M7KU47mp3vyI5sZmtCuwHrAZ0B142sxXdvaJBoxYREREpYaqxFREpIHf/1d0/jP+fBnwJ9Mgxy67AA+4+x92/B0YD69Z/pCIiIiKLDiW2IiL1xMz6AGsC/4uDjjOzT83sTjPrGIf1AH5KzDaWDImwmR1pZiPMbMTEiRPrM2wRERGRkqPEVkSkHphZG+BR4CR3nwrcDCwH9AN+Ba5MTZphdl9ogPtt7t7f3ft37ty5foIWERERKVFKbEVECszMmhKS2nvd/TEAdx/v7hXuXgnczoLmxmOBXonZewK/NGS8IiIiIqVOia2ISAGZmQGDgC/d/arE8G6JyXYHPov/fwrYz8yam9kywArAew0Vr4iIiMiiQL0ii4gU1kbAwcBIM/s4DjsL2N/M+hGaGY8BjgJw98/N7CHgC0KPyseqR2QRERGRmlFiKyJSQO7+Fpmfm302xzwXAxfXW1AiIiIiizg1RRYREREREZGSpsRWRERERERESpoSWxERERERESlpSmxFRERERESkpCmxFRERERERkZKmxFZERERERERKmhJbERERERERKWlKbEVEpCTMnTuXSZMmFTsMERERaYSU2IqISEn47bffeO6554odhoiIiDRCSmxFRKQkdOvWjYMPPrjYYYiIiEgjpMRWRERERERESpoSWxERERERESlpSmxFRERERESkpCmxFRERERERkZKmxFZERERERERKmhJbERERERERKWlKbEVERERERKSkKbEVERERERGRkqbEVkREREREREqaElsREREREREpaUpsRUREREREpKQpsRUREREREZGSpsRWRERERERESpq5e7FjEBGRGjCzicAMYFKxY0nTicYXEyiummqMcRUjpqXdvXMDL1NERGpJia2ISAkysxHu3r/YcSQ1xphAcdVUY4yrMcYkIiKNi5oii4iIiIiISElTYisiIiIiIiIlTYmtiEhpuq3YAWTQGGMCxVVTjTGuxhiTiIg0InrGVkREREREREqaamxFRERERESkpCmxFRERERERkZKmxFZEpISY2fZmNsrMRpvZGUWOZYyZjTSzj81sRBy2hJm9ZGbfxH87NkAcd5rZBDP7LDEsaxxmdmbcfqPMbLsGjOk8M/s5bq+PzWzHhowpLqeXmb1mZl+a2edmdmIcXuztlS2uom8zEREpDXrGVkSkRJhZOfA1sA0wFngf2N/dvyhSPGOA/u4+KTHscmCyu/87Jt4d3f30eo5jU2A6cJe7r54rDjNbFbgfWBfoDrwMrOjuFQ0Q03nAdHe/Im3aBokpLqsb0M3dPzSztsAHwG7AIRR3e2WLax+KvM1ERKQ0qMZWRKR0rAuMdvfv3H0u8ACwa5FjSrcrMDT+fyghOalX7v4GMDnPOHYFHnD3Oe7+PTCasF0bIqZsGiSmGNev7v5h/P804EugB8XfXtniyqbBtpmIiJQGJbYiIqWjB/BT4u+x5L74r28OvGhmH5jZkXFYV3f/FUKyAnQpUmzZ4ij2NjzOzD6NTZVTzX2LEpOZ9QHWBP5HI9peaXFBI9pmIiLSeCmxFREpHZZhWDGfJ9nI3dcCdgCOjc1vG7tibsObgeWAfsCvwJXFisnM2gCPAie5+9Rck2YYVm+xZYir0WwzERFp3JTYioiUjrFAr8TfPYFfihQL7v5L/HcC8DihKej4+Lxk6rnJCUUKL1scRduG7j7e3SvcvRK4nQVNZxs0JjNrSkge73X3x+Lgom+vTHE1lm0mIiKNnxJbEZHS8T6wgpktY2bNgP2Ap4oRiJm1jp38YGatgW2Bz2I8A+NkA4EnixFfjjieAvYzs+ZmtgywAvBeQwSUShyj3Qnbq0FjMjMDBgFfuvtViVFF3V7Z4moM20xEREpDk2IHICIi+XH3+WZ2HPACUA7c6e6fFymcrsDjIR+hCXCfuz9vZu8DD5nZ4cCPwN71HYiZ3Q9sDnQys7HAucC/M8Xh7p+b2UPAF8B84Nh66n04U0ybm1k/QpPZMcBRDRlTtBFwMDDSzD6Ow86iyNsrR1z7N4JtJiIiJUCv+xEREREREZGSpqbIIiIiIiIiUtKU2IqIiIiIiEhJU2IrIiIiIiIiJU2JrYiIiIiIiJQ0JbYiIiIiIiJS0pTYioiIiIiISElTYisiIiIiIiIl7f8B/ZtK9EUKu7UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1) : \n",
    "    image, label, label_length = trainset[i]\n",
    "    text = tokenizer.sequence_to_text(label.numpy())\n",
    "    plt.imshow(image.transpose(0, 1).transpose(1, 2))\n",
    "    plt.title(f'label: {label}  text: {text}  label_length: {label_length}')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "272a4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e44617",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "557365a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    model = timm.create_model(CFG.model_name, pretrained = False)\n",
    "    model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d66b6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    out_test_val = torch.randn(2, 3, 224, 224)\n",
    "    print(out_test_val.shape)\n",
    "    out_test = model(out_test_val)\n",
    "    print(f'shape : {out_test.shape}')\n",
    "    model.global_pool = nn.Identity()\n",
    "    model.fc = nn.Identity()\n",
    "    model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07fb97a",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6712553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) : \n",
    "    def __init__(self, model_name = CFG.model_name, pretrained = False) :\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model(model_name, pretrained = pretrained)\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        bs = x.size(0)\n",
    "        features = self.cnn.forward_features(x)\n",
    "        features = features.permute(0, 2, 3, 1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58239cd2",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50f2f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module) : \n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim) : \n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)\n",
    "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)\n",
    "        self.full_att = nn.Linear(attention_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, encoder_out, decoder_hidden) : \n",
    "        att1 = self.encoder_att(encoder_out)\n",
    "        att2 = self.decoder_att(decoder_hidden)\n",
    "        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)\n",
    "        alpha = self.softmax(att)\n",
    "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim = 1)\n",
    "        return attention_weighted_encoding, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd9c1f",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb290838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTMCell(input_size, hidden_size, **kwargs):\n",
    "    m = nn.LSTMCell(input_size, hidden_size, **kwargs)\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6a275be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithAttention(nn.Module) : \n",
    "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, device, encoder_dim, dropout, num_layers):\n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "        self.encoder_dim   = encoder_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.embed_dim     = embed_dim\n",
    "        self.decoder_dim   = decoder_dim\n",
    "        self.vocab_size    = vocab_size\n",
    "        self.dropout       = dropout\n",
    "        self.num_layers    = num_layers\n",
    "        self.device        = device\n",
    "        self.attention     = Attention(encoder_dim, decoder_dim, attention_dim)  # attention network\n",
    "        self.embedding     = nn.Embedding(vocab_size, embed_dim)                 # embedding layer\n",
    "        self.dropout       = nn.Dropout(p = self.dropout)\n",
    "        self.decode_step   = nn.ModuleList([LSTMCell(embed_dim + encoder_dim if layer == 0 else embed_dim, embed_dim) for layer in range(self.num_layers)]) # decoding LSTMCell        \n",
    "        self.init_h        = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial hidden state of LSTMCell\n",
    "        self.init_c        = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial cell state of LSTMCell\n",
    "        self.f_beta        = nn.Linear(decoder_dim, encoder_dim)  # linear layer to create a sigmoid-activated gate\n",
    "        self.sigmoid       = nn.Sigmoid()\n",
    "        self.fc            = nn.Linear(decoder_dim, vocab_size)  # linear layer to find scores over vocabulary\n",
    "        self.init_weights()                                      # initialize some layers with the uniform distribution\n",
    "        \n",
    "    def init_weights(self) : \n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings) : \n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tune_embeddings(self, fine_tune = True) : \n",
    "        for p in self.embedding.parameters() : \n",
    "            p.requires_grad = fine_tune\n",
    "            \n",
    "    def init_hidden_state(self, encoder_out) : \n",
    "        mean_encoder_out = encoder_out.mean(dim = 1)\n",
    "        h = [self.init_h(mean_encoder_out) for i in range(self.num_layers)]  # (batch_size, decoder_dim)\n",
    "        c = [self.init_c(mean_encoder_out) for i in range(self.num_layers)]\n",
    "        return h, c\n",
    "    \n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
    "        '''\n",
    "        :param encoder_out: output of encoder network\n",
    "        :param encoded_captions: transformed sequence from character to integer\n",
    "        :param caption_lengths: length of transformed sequence\n",
    "        '''\n",
    "        batch_size       = encoder_out.size(0)\n",
    "        encoder_dim      = encoder_out.size(-1)\n",
    "        vocab_size       = self.vocab_size\n",
    "        encoder_out      = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels       = encoder_out.size(1)\n",
    "        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim = 0, descending = True)\n",
    "        encoder_out      = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "        \n",
    "        # embedding transformed sequence for vector\n",
    "        embeddings = self.embedding(encoded_captions)  # (batch_size, max_caption_length, embed_dim)\n",
    "        \n",
    "        # Initialize LSTM state, initialize cell_vector and hidden_vector\n",
    "        prev_h, prev_c = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "        \n",
    "        # set decode length by caption length - 1 because of omitting start token\n",
    "        decode_lengths = (caption_lengths - 1).tolist()\n",
    "        predictions    = torch.zeros(batch_size, max(decode_lengths), vocab_size, device = self.device)\n",
    "        alphas         = torch.zeros(batch_size, max(decode_lengths), num_pixels, device = self.device)\n",
    "        \n",
    "        # predict sequence\n",
    "        for t in range(max(decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in decode_lengths])\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],\n",
    "                                                                prev_h[-1][:batch_size_t])\n",
    "            gate = self.sigmoid(self.f_beta(prev_h[-1][:batch_size_t]))  # gating scalar, (batch_size_t, encoder_dim)\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "\n",
    "            input = torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1)\n",
    "            \n",
    "            for i, rnn in enumerate(self.decode_step):\n",
    "                # recurrent cell\n",
    "                h, c = rnn(input, (prev_h[i][:batch_size_t], prev_c[i][:batch_size_t])) # cell_vector and hidden_vector\n",
    "\n",
    "                # hidden state becomes the input to the next layer\n",
    "                input = self.dropout(h)\n",
    "\n",
    "                # save state for next time step\n",
    "                prev_h[i] = h\n",
    "                prev_c[i] = c\n",
    "                \n",
    "            preds = self.fc(self.dropout(h))  # (batch_size_t, vocab_size)\n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "            alphas[:batch_size_t, t, :]      = alpha\n",
    "            \n",
    "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind\n",
    "    \n",
    "    def predict(self, encoder_out, decode_lengths, tokenizer):\n",
    "        \n",
    "        # size variables\n",
    "        batch_size  = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size  = self.vocab_size\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels  = encoder_out.size(1)\n",
    "        \n",
    "        # embed start tocken for LSTM input\n",
    "        start_tockens = torch.ones(batch_size, dtype = torch.long, device = self.device) * tokenizer.stoi['<sos>']\n",
    "        embeddings    = self.embedding(start_tockens)\n",
    "        \n",
    "        # initialize hidden state and cell state of LSTM cell\n",
    "        h, c        = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "        predictions = torch.zeros(batch_size, decode_lengths, vocab_size, device = self.device)\n",
    "        \n",
    "        # predict sequence\n",
    "        end_condition = torch.zeros(batch_size, dtype=torch.long, device = self.device)\n",
    "        for t in range(decode_lengths):\n",
    "            awe, alpha = self.attention(encoder_out, h[-1])  # (s, encoder_dim), (s, num_pixels)\n",
    "            gate       = self.sigmoid(self.f_beta(h[-1]))    # gating scalar, (s, encoder_dim)\n",
    "            awe        = gate * awe\n",
    "            \n",
    "            input = torch.cat([embeddings, awe], dim=1)\n",
    " \n",
    "            for j, rnn in enumerate(self.decode_step):\n",
    "                at_h, at_c = rnn(input, (h[j], c[j]))  # (s, decoder_dim)\n",
    "                input = self.dropout(at_h)\n",
    "                h[j]  = at_h\n",
    "                c[j]  = at_c\n",
    "            \n",
    "            preds = self.fc(self.dropout(h[-1]))  # (batch_size_t, vocab_size)\n",
    "            predictions[:, t, :] = preds\n",
    "            end_condition |= (torch.argmax(preds, -1) == tokenizer.stoi[\"<eos>\"])\n",
    "            if end_condition.sum() == batch_size:\n",
    "                break\n",
    "            embeddings = self.embedding(torch.argmax(preds, -1))\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    # beam search\n",
    "    def forward_step(self, prev_tokens, hidden, encoder_out, function):\n",
    "        \n",
    "        h, c = hidden\n",
    "        #h, c = h.squeeze(0), c.squeeze(0)\n",
    "        h, c = [hi.squeeze(0) for hi in h], [ci.squeeze(0) for ci in c]\n",
    "        \n",
    "        embeddings = self.embedding(prev_tokens)\n",
    "        if embeddings.dim() == 3:\n",
    "            embeddings = embeddings.squeeze(1)\n",
    "            \n",
    "        awe, alpha = self.attention(encoder_out, h[-1])  # (s, encoder_dim), (s, num_pixels)\n",
    "        gate       = self.sigmoid(self.f_beta(h[-1]))    # gating scalar, (s, encoder_dim)\n",
    "        awe        = gate * awe\n",
    "        \n",
    "        input = torch.cat([embeddings, awe], dim = 1)\n",
    "        for j, rnn in enumerate(self.decode_step):\n",
    "            at_h, at_c = rnn(input, (h[j], c[j]))  # (s, decoder_dim)\n",
    "            input = self.dropout(at_h)\n",
    "            h[j]  = at_h\n",
    "            c[j]  = at_c\n",
    "\n",
    "        preds = self.fc(self.dropout(h[-1]))  # (batch_size_t, vocab_size)\n",
    "\n",
    "        #hidden = (h.unsqueeze(0), c.unsqueeze(0))\n",
    "        hidden = [hi.unsqueeze(0) for hi in h], [ci.unsqueeze(0) for ci in c]\n",
    "        predicted_softmax = function(preds, dim = 1)\n",
    "        \n",
    "        return predicted_softmax, hidden, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2d04dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    embedding = nn.Embedding(30, 512)\n",
    "    print(embedding.weight.data)\n",
    "    print(embedding.weight.data.uniform_(-0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecc2d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    fc = nn.Linear(512, 30)\n",
    "    fc.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26c2c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    rnd = torch.randn(2, 3, 224, 224)\n",
    "    print(rnd)\n",
    "    nn.Parameter(rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4812c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    rnd = torch.randn(2, 8, 4, 2)\n",
    "    print(rnd.shape)\n",
    "    rnd = rnd.mean(dim = 1)\n",
    "    print(rnd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32737581",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    rnd = torch.randn(8, 1)\n",
    "    print(rnd)\n",
    "    rnd = rnd.squeeze(1)\n",
    "    print(rnd)\n",
    "    rnd = rnd.sort(dim = 0, descending = True)\n",
    "    print(rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edc7b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    dleng = [5, 9]\n",
    "    for t in range(max(dleng)) : \n",
    "        batch_size_t = sum([l > t for l in dleng])\n",
    "        print(batch_size_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2457972",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug == True :\n",
    "    start_tokens = torch.ones(16, dtype = torch.long).to(DEVICE) * tokenizer.stoi[\"<sos>\"]\n",
    "    start_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc35203",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18d99f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred) : \n",
    "    scores = []\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred) : \n",
    "        score = Levenshtein.distance(true, pred)\n",
    "        scores.append(score)\n",
    "        \n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a18527ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5228c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed = 0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed = CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "996ade2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object) : \n",
    "    def __init__(self) : \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self) : \n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n = 1) : \n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78812c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "834f08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bms_collate(batch):\n",
    "    imgs, labels, label_lengths = [], [], []\n",
    "    for data_point in batch:\n",
    "        imgs.append(data_point[0])\n",
    "        labels.append(data_point[1])\n",
    "        label_lengths.append(data_point[2])\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.stoi[\"<pad>\"])\n",
    "    return torch.stack(imgs), labels, torch.stack(label_lengths).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9e8bf",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba47c153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0    1984645\n",
      "1    1984645\n",
      "2    1984644\n",
      "3    1984644\n",
      "4    1984644\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['InChI_length'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "    \n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cca7f8c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0300f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch,\n",
    "             encoder_scheduler, decoder_scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    for step, (images, labels, label_lengths) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        features = encoder(images)\n",
    "        \n",
    "        predictions, caps_sorted, decode_lengths, alphas, sort_ind = decoder(features, labels, label_lengths)\n",
    "        targets = caps_sorted[:, 1:]\n",
    "        predictions = pack_padded_sequence(predictions, decode_lengths, batch_first=True).data\n",
    "        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "        \n",
    "        loss = criterion(predictions, targets)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_grad_norm = torch.nn.utils.clip_grad_norm_(encoder.parameters(), CFG.max_grad_norm)\n",
    "        decoder_grad_norm = torch.nn.utils.clip_grad_norm_(decoder.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Encoder Grad: {encoder_grad_norm:.4f}  '\n",
    "                  'Decoder Grad: {decoder_grad_norm:.4f}  '\n",
    "                  #'Encoder LR: {encoder_lr:.6f}  '\n",
    "                  #'Decoder LR: {decoder_lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch + 1, step, len(train_loader), batch_time = batch_time,\n",
    "                   data_time = data_time, loss = losses,\n",
    "                   remain = timeSince(start, float(step + 1)/len(train_loader)),\n",
    "                   encoder_grad_norm = encoder_grad_norm,\n",
    "                   decoder_grad_norm = decoder_grad_norm,\n",
    "                   #encoder_lr=encoder_scheduler.get_lr()[0],\n",
    "                   #decoder_lr=decoder_scheduler.get_lr()[0],\n",
    "                   ))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aeb45aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, device) : \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    text_preds = []\n",
    "    start = end = time.time()\n",
    "    \n",
    "    for step, (images) in enumerate(valid_loader) : \n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad() : \n",
    "            features = encoder(images)\n",
    "            predictions = decoder.predict(features, CFG.max_len, tokenizer)\n",
    "        \n",
    "        predicted_sequence = torch.argmax(predictions.detach().cpu(), -1).numpy()\n",
    "        _text_preds = tokenizer.predict_captions(predicted_sequence)\n",
    "        text_preds.append(_text_preds)\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1) :\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), batch_time = batch_time,\n",
    "                   data_time = data_time,\n",
    "                   remain = timeSince(start, float(step + 1)/len(valid_loader)),\n",
    "                   ))\n",
    "            \n",
    "    text_preds = np.concatenate(text_preds)\n",
    "    return text_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f58386c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "    train_folds  = folds.loc[trn_idx].reset_index(drop = True)\n",
    "    valid_folds  = folds.loc[val_idx].reset_index(drop = True)\n",
    "    valid_labels = valid_folds['InChI'].values\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, tokenizer, transform = get_transforms(data = 'train'))\n",
    "    valid_dataset = TestDataset(valid_folds, transform = get_transforms(data = 'valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size  = CFG.batch_size, \n",
    "                              shuffle     = True, \n",
    "                              num_workers = CFG.num_workers, \n",
    "                              pin_memory  = True,\n",
    "                              drop_last   = True, \n",
    "                              collate_fn  = bms_collate)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size  = CFG.batch_size, \n",
    "                              shuffle     = False, \n",
    "                              num_workers = CFG.num_workers,\n",
    "                              pin_memory  = True, \n",
    "                              drop_last   = False)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                          mode     = 'min', \n",
    "                                          factor   = CFG.factor, \n",
    "                                          patience = CFG.patience, \n",
    "                                          verbose  = True, \n",
    "                                          eps      = CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, \n",
    "                                          T_max      = CFG.T_max, \n",
    "                                          eta_min    = CFG.min_lr, \n",
    "                                          last_epoch = -1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                    T_0        = CFG.T_0, \n",
    "                                                    T_mult     = 1, \n",
    "                                                    eta_min    = CFG.min_lr, \n",
    "                                                    last_epoch = -1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "\n",
    "    #states = torch.load(CFG.prev_model,  map_location = torch.device('cpu'))\n",
    "\n",
    "    encoder = Encoder(CFG.model_name, \n",
    "                      pretrained = True)\n",
    "    #encoder.load_state_dict(states['encoder'])\n",
    "    \n",
    "    encoder.to(DEVICE)\n",
    "    encoder_optimizer = Adam(encoder.parameters(), \n",
    "                             lr           = CFG.encoder_lr, \n",
    "                             weight_decay = CFG.weight_decay, \n",
    "                             amsgrad      = False)\n",
    "    #encoder_optimizer.load_state_dict(states['encoder_optimizer'])\n",
    "    encoder_scheduler = get_scheduler(encoder_optimizer)\n",
    "    #encoder_scheduler.load_state_dict(states['encoder_scheduler'])\n",
    "    \n",
    "    decoder = DecoderWithAttention(attention_dim = CFG.attention_dim, \n",
    "                                   embed_dim     = CFG.embed_dim, \n",
    "                                   encoder_dim   = CFG.enc_size,\n",
    "                                   decoder_dim   = CFG.decoder_dim,\n",
    "                                   num_layers    = CFG.decoder_layers,\n",
    "                                   vocab_size    = len(tokenizer), \n",
    "                                   dropout       = CFG.dropout, \n",
    "                                   device        = DEVICE)\n",
    "    #decoder.load_state_dict(states['decoder'])\n",
    "    decoder.to(DEVICE)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), \n",
    "                             lr           = CFG.decoder_lr, \n",
    "                             weight_decay = CFG.weight_decay, \n",
    "                             amsgrad      = False)\n",
    "    #decoder_optimizer.load_state_dict(states['decoder_optimizer'])\n",
    "\n",
    "    decoder_scheduler = get_scheduler(decoder_optimizer)\n",
    "    #decoder_scheduler.load_state_dict(states['decoder_scheduler'])\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.stoi[\"<pad>\"])\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_loss  = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, encoder, decoder, criterion, \n",
    "                            encoder_optimizer, decoder_optimizer, epoch, \n",
    "                            encoder_scheduler, decoder_scheduler, DEVICE)\n",
    "\n",
    "        # eval\n",
    "        text_preds = valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, DEVICE)\n",
    "        text_preds = [f\"InChI=1S/{text}\" for text in text_preds]\n",
    "        LOGGER.info(f\"labels: {valid_labels[:5]}\")\n",
    "        LOGGER.info(f\"preds: {text_preds[:5]}\")\n",
    "        \n",
    "        # scoring\n",
    "        score = get_score(valid_labels, text_preds)\n",
    "        \n",
    "        if isinstance(encoder_scheduler, ReduceLROnPlateau):\n",
    "            encoder_scheduler.step(score)\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingLR):\n",
    "            encoder_scheduler.step()\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            encoder_scheduler.step()\n",
    "            \n",
    "        if isinstance(decoder_scheduler, ReduceLROnPlateau):\n",
    "            decoder_scheduler.step(score)\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingLR):\n",
    "            decoder_scheduler.step()\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            decoder_scheduler.step()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'encoder': encoder.state_dict(), \n",
    "                        'encoder_optimizer': encoder_optimizer.state_dict(), \n",
    "                        'encoder_scheduler': encoder_scheduler.state_dict(), \n",
    "                        'decoder': decoder.state_dict(), \n",
    "                        'decoder_optimizer': decoder_optimizer.state_dict(), \n",
    "                        'decoder_scheduler': decoder_scheduler.state_dict(), \n",
    "                        'text_preds': text_preds,\n",
    "                       },\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0864c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() : \n",
    "    if CFG.train : \n",
    "        oof_df = pd.DataFrame()\n",
    "        \n",
    "        for fold in range(CFG.n_fold) : \n",
    "            if fold in CFG.trn_fold : \n",
    "                train_loop(folds, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52b78d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/25] Data 0.173 (0.173) Elapsed 0m 1s (remain 0m 29s) Loss: 6.5840(6.5840) Encoder Grad: 0.7226  Decoder Grad: 0.9260  \n",
      "Epoch: [1][1/25] Data 0.164 (0.169) Elapsed 0m 2s (remain 0m 23s) Loss: 6.4494(6.5167) Encoder Grad: 0.6151  Decoder Grad: 1.2206  \n",
      "Epoch: [1][2/25] Data 0.108 (0.149) Elapsed 0m 2s (remain 0m 20s) Loss: 6.1511(6.3948) Encoder Grad: 0.8615  Decoder Grad: 1.7373  \n",
      "Epoch: [1][3/25] Data 0.089 (0.134) Elapsed 0m 3s (remain 0m 18s) Loss: 5.7612(6.2364) Encoder Grad: 1.3392  Decoder Grad: 1.4869  \n",
      "Epoch: [1][4/25] Data 0.092 (0.125) Elapsed 0m 4s (remain 0m 16s) Loss: 5.4957(6.0883) Encoder Grad: 1.9619  Decoder Grad: 1.7158  \n",
      "Epoch: [1][5/25] Data 0.102 (0.121) Elapsed 0m 4s (remain 0m 15s) Loss: 5.1708(5.9354) Encoder Grad: 1.6072  Decoder Grad: 1.5596  \n",
      "Epoch: [1][6/25] Data 0.091 (0.117) Elapsed 0m 5s (remain 0m 14s) Loss: 4.9354(5.7925) Encoder Grad: 2.1670  Decoder Grad: 1.4910  \n",
      "Epoch: [1][7/25] Data 0.098 (0.115) Elapsed 0m 6s (remain 0m 13s) Loss: 4.7633(5.6639) Encoder Grad: 0.5046  Decoder Grad: 2.0608  \n",
      "Epoch: [1][8/25] Data 0.086 (0.111) Elapsed 0m 7s (remain 0m 12s) Loss: 4.5929(5.5449) Encoder Grad: 0.5655  Decoder Grad: 1.7412  \n",
      "Epoch: [1][9/25] Data 0.104 (0.111) Elapsed 0m 7s (remain 0m 11s) Loss: 4.3607(5.4264) Encoder Grad: 0.4624  Decoder Grad: 1.2272  \n",
      "Epoch: [1][10/25] Data 0.111 (0.111) Elapsed 0m 8s (remain 0m 11s) Loss: 4.2940(5.3235) Encoder Grad: 0.3807  Decoder Grad: 0.9960  \n",
      "Epoch: [1][11/25] Data 0.117 (0.111) Elapsed 0m 9s (remain 0m 10s) Loss: 4.2139(5.2310) Encoder Grad: 0.2138  Decoder Grad: 1.2079  \n",
      "Epoch: [1][12/25] Data 0.083 (0.109) Elapsed 0m 10s (remain 0m 9s) Loss: 4.0873(5.1430) Encoder Grad: 0.1904  Decoder Grad: 1.2563  \n",
      "Epoch: [1][13/25] Data 0.096 (0.108) Elapsed 0m 10s (remain 0m 8s) Loss: 4.0202(5.0628) Encoder Grad: 0.1767  Decoder Grad: 1.1431  \n",
      "Epoch: [1][14/25] Data 0.100 (0.108) Elapsed 0m 11s (remain 0m 7s) Loss: 3.9421(4.9881) Encoder Grad: 0.1357  Decoder Grad: 0.9294  \n",
      "Epoch: [1][15/25] Data 0.083 (0.106) Elapsed 0m 12s (remain 0m 6s) Loss: 3.8733(4.9185) Encoder Grad: 0.1308  Decoder Grad: 0.8538  \n",
      "Epoch: [1][16/25] Data 0.083 (0.105) Elapsed 0m 13s (remain 0m 6s) Loss: 3.9441(4.8611) Encoder Grad: 0.1339  Decoder Grad: 0.7980  \n",
      "Epoch: [1][17/25] Data 0.096 (0.104) Elapsed 0m 13s (remain 0m 5s) Loss: 3.7906(4.8017) Encoder Grad: 0.0900  Decoder Grad: 1.0099  \n",
      "Epoch: [1][18/25] Data 0.103 (0.104) Elapsed 0m 14s (remain 0m 4s) Loss: 3.8088(4.7494) Encoder Grad: 0.0940  Decoder Grad: 0.8315  \n",
      "Epoch: [1][19/25] Data 0.121 (0.105) Elapsed 0m 15s (remain 0m 3s) Loss: 3.7369(4.6988) Encoder Grad: 0.1062  Decoder Grad: 0.6489  \n",
      "Epoch: [1][20/25] Data 0.133 (0.106) Elapsed 0m 16s (remain 0m 3s) Loss: 3.6841(4.6505) Encoder Grad: 0.0787  Decoder Grad: 0.6490  \n",
      "Epoch: [1][21/25] Data 0.114 (0.107) Elapsed 0m 16s (remain 0m 2s) Loss: 3.6748(4.6061) Encoder Grad: 0.0808  Decoder Grad: 0.7186  \n",
      "Epoch: [1][22/25] Data 0.106 (0.107) Elapsed 0m 17s (remain 0m 1s) Loss: 3.6310(4.5637) Encoder Grad: 0.0777  Decoder Grad: 0.7460  \n",
      "Epoch: [1][23/25] Data 0.094 (0.106) Elapsed 0m 18s (remain 0m 0s) Loss: 3.7305(4.5290) Encoder Grad: 0.0753  Decoder Grad: 0.8467  \n",
      "Epoch: [1][24/25] Data 0.094 (0.106) Elapsed 0m 19s (remain 0m 0s) Loss: 3.7283(4.4970) Encoder Grad: 0.1198  Decoder Grad: 0.8259  \n",
      "EVAL: [0/7] Data 0.099 (0.099) Elapsed 0m 0s (remain 0m 2s) \n",
      "EVAL: [1/7] Data 0.087 (0.093) Elapsed 0m 0s (remain 0m 2s) \n",
      "EVAL: [2/7] Data 0.082 (0.089) Elapsed 0m 1s (remain 0m 1s) \n",
      "EVAL: [3/7] Data 0.107 (0.094) Elapsed 0m 1s (remain 0m 1s) \n",
      "EVAL: [4/7] Data 0.107 (0.096) Elapsed 0m 2s (remain 0m 0s) \n",
      "EVAL: [5/7] Data 0.106 (0.098) Elapsed 0m 2s (remain 0m 0s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labels: ['InChI=1S/C9H6N2O3/c12-11(13)8-6-14-10-9(8)7-4-2-1-3-5-7/h1-6H'\n",
      " 'InChI=1S/C10H11F2IN6OS/c1-3-21-10-15-14-8(7(11)12)19(10)17-9(20)6-5(13)4-18(2)16-6/h4,7H,3H2,1-2H3,(H,17,20)'\n",
      " 'InChI=1S/C26H25BrN2O5/c1-16-8-10-20(11-9-16)26(31)34-25-21(27)12-19(13-23(25)32-4)14-28-29-24(30)15-33-22-7-5-6-17(2)18(22)3/h5-14H,15H2,1-4H3,(H,29,30)/b28-14+'\n",
      " 'InChI=1S/C16H18ClN3O4/c1-8-14(9(2)20(4)19-8)18-15(22)10(3)24-16(23)12-6-5-11(17)7-13(12)21/h5-7,10,21H,1-4H3,(H,18,22)/t10-/m0/s1'\n",
      " 'InChI=1S/C10H9N3O2/c11-7-3-1-2-6(4-7)8-5-12-10(15)13-9(8)14/h1-5H,11H2,(H2,12,13,14,15)']\n",
      "preds: ['InChI=1S/CHHHHH-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', 'InChI=1S/CHHHH------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', 'InChI=1S/CHHHHH-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', 'InChI=1S/CHHHHH-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', 'InChI=1S/CHHHH------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------']\n",
      "Epoch 1 - avg_train_loss: 4.4970  time: 22s\n",
      "Epoch 1 - Score: 252.8450\n",
      "Epoch 1 - Save Best Score: 252.8450 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [6/7] Data 0.029 (0.088) Elapsed 0m 2s (remain 0m 0s) \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' : \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab70c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
